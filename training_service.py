#!/usr/bin/env python3
"""
GPT-SoVITSËÆ≠ÁªÉÊúçÂä°API
Êèê‰æõÂÆåÊï¥ÁöÑËØ≠Èü≥ÂÖãÈöÜËÆ≠ÁªÉÊµÅÁ®ãAPIÊé•Âè£
"""

import os
import sys
import json
import uuid
import asyncio
import subprocess
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path
from enum import Enum

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field
import uvicorn

# ÂØºÂÖ•Ê≠•È™§Â§ÑÁêÜÂô®ÂíåÈÖçÁΩÆ
from training_steps import StepProcessor, ConfigGenerator
from service_config import get_base_path, get_work_dir, get_model_paths

# ÈÖçÁΩÆÊó•Âøó
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('training_service.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ‰ªªÂä°Áä∂ÊÄÅÊûö‰∏æ
class TaskStatus(str, Enum):
    CREATED = "created"
    RUNNING = "running" 
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

# ËÆ≠ÁªÉÊ≠•È™§Êûö‰∏æ
class TrainingStep(str, Enum):
    CONVERT_AUDIO = "convert_audio"
    SLICE_AUDIO = "slice_audio"
    DENOISE_AUDIO = "denoise_audio"
    ASR_TRANSCRIBE = "asr_transcribe"
    EXTRACT_TEXT_FEATURES = "extract_text_features"
    EXTRACT_AUDIO_FEATURES = "extract_audio_features"
    EXTRACT_SPEAKER_VECTORS = "extract_speaker_vectors"
    EXTRACT_SEMANTIC_FEATURES = "extract_semantic_features"
    TRAIN_SOVITS = "train_sovits"
    TRAIN_GPT = "train_gpt"
    TEST_INFERENCE = "test_inference"

# Êï∞ÊçÆÊ®°Âûã
class TaskConfig(BaseModel):
    exp_name: str = Field(default="my_speaker", description="ÂÆûÈ™åÂêçÁß∞")
    language: str = Field(default="zh", description="ËØ≠Ë®ÄËÆæÁΩÆ")
    batch_size: int = Field(default=16, description="ÊâπÊ¨°Â§ßÂ∞è")
    epochs_s2: int = Field(default=50, description="SoVITSËÆ≠ÁªÉËΩÆÊï∞")
    epochs_s1: int = Field(default=15, description="GPTËÆ≠ÁªÉËΩÆÊï∞")
    gpu_id: str = Field(default=os.environ.get("CUDA_VISIBLE_DEVICES", "0"), description="GPUËÆæÂ§áID")

class TaskCreateRequest(BaseModel):
    task_name: str = Field(description="‰ªªÂä°ÂêçÁß∞")
    config: TaskConfig = Field(description="ËÆ≠ÁªÉÈÖçÁΩÆ")

class TaskInfo(BaseModel):
    task_id: str
    task_name: str
    status: TaskStatus
    config: TaskConfig
    created_at: datetime
    updated_at: datetime
    current_step: Optional[str] = None
    progress: float = 0.0
    error_message: Optional[str] = None

class StepExecuteRequest(BaseModel):
    params: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Ê≠•È™§ÁâπÂÆöÂèÇÊï∞")

# ÂÖ®Â±Ä‰ªªÂä°Â≠òÂÇ®
tasks_db: Dict[str, TaskInfo] = {}
step_processes: Dict[str, subprocess.Popen] = {}

# FastAPIÂ∫îÁî®
app = FastAPI(
    title="GPT-SoVITSËÆ≠ÁªÉÊúçÂä°",
    description="Êèê‰æõÂÆåÊï¥ÁöÑËØ≠Èü≥ÂÖãÈöÜËÆ≠ÁªÉÊµÅÁ®ãAPIÊé•Âè£",
    version="1.0.0"
)

class TrainingService:
    """ËÆ≠ÁªÉÊúçÂä°Ê†∏ÂøÉÁ±ª"""
    
    def __init__(self):
        # ‰ΩøÁî®ÈÖçÁΩÆÊñá‰ª∂Ëé∑ÂèñË∑ØÂæÑ
        self.base_dir = get_base_path()
        self.work_dir = get_work_dir()
        
        self.step_processor = StepProcessor(str(self.base_dir))
        self.config_generator = ConfigGenerator(str(self.base_dir))
        
        logger.info(f"‚úÖ ÂàùÂßãÂåñÂÆåÊàê:")
        logger.info(f"   Âü∫Á°ÄÁõÆÂΩï: {self.base_dir}")
        logger.info(f"   Â∑•‰ΩúÁõÆÂΩï: {self.work_dir}")
    
    def get_task_dir(self, task_id: str) -> Path:
        """Ëé∑Âèñ‰ªªÂä°Â∑•‰ΩúÁõÆÂΩï"""
        task_dir = self.work_dir / task_id
        task_dir.mkdir(exist_ok=True)
        return task_dir
    
    def get_task_input_dir(self, task_id: str) -> Path:
        """Ëé∑Âèñ‰ªªÂä°ËæìÂÖ•ÁõÆÂΩï"""
        input_dir = self.get_task_dir(task_id) / "input_audio"
        input_dir.mkdir(exist_ok=True)
        return input_dir
    
    def get_task_output_dir(self, task_id: str) -> Path:
        """Ëé∑Âèñ‰ªªÂä°ËæìÂá∫ÁõÆÂΩï"""
        output_dir = self.get_task_dir(task_id) / "output"
        output_dir.mkdir(exist_ok=True)
        return output_dir
    
    def create_task_config_file(self, task_id: str, config: TaskConfig) -> Path:
        """ÂàõÂª∫‰ªªÂä°ÈÖçÁΩÆÊñá‰ª∂"""
        task_dir = self.get_task_dir(task_id)
        config_file = task_dir / "task_config.json"
        
        # Ëé∑ÂèñÊ®°ÂûãË∑ØÂæÑÈÖçÁΩÆ
        model_paths = get_model_paths()
        
        # Âü∫‰∫éÂéüÂßãËÑöÊú¨ÁöÑÈÖçÁΩÆÁªìÊûÑ
        task_config = {
            "INPUT_AUDIO": str(self.get_task_input_dir(task_id)),
            "WORK_DIR": str(task_dir),
            "EXP_NAME": config.exp_name,
            "EXP_DIR": str(task_dir / "experiments" / config.exp_name),
            "SLICED_DIR": str(task_dir / "sliced"),
            "DENOISED_DIR": str(task_dir / "denoised"), 
            "ASR_OUTPUT": str(task_dir / "transcripts"),
            "BERT_DIR": model_paths["bert_dir"],
            "CNHUBERT_DIR": model_paths["cnhubert_dir"],
            "PRETRAINED_SV": model_paths["pretrained_sv"],
            "BATCH_SIZE": config.batch_size,
            "EPOCHS_S2": config.epochs_s2,
            "EPOCHS_S1": config.epochs_s1,
            "GPU_ID": config.gpu_id,
            "LANGUAGE": config.language
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(task_config, f, indent=2, ensure_ascii=False)
        
        return config_file
    
    def load_task_config(self, task_id: str) -> Dict[str, Any]:
        """Âä†ËΩΩ‰ªªÂä°ÈÖçÁΩÆ"""
        config_file = self.get_task_dir(task_id) / "task_config.json"
        if not config_file.exists():
            raise FileNotFoundError(f"‰ªªÂä°ÈÖçÁΩÆÊñá‰ª∂‰∏çÂ≠òÂú®: {config_file}")
        
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    async def execute_step(self, task_id: str, step: TrainingStep, params: Dict[str, Any] = None):
        """ÊâßË°åËÆ≠ÁªÉÊ≠•È™§"""
        if task_id not in tasks_db:
            raise HTTPException(status_code=404, detail="‰ªªÂä°‰∏çÂ≠òÂú®")
        
        task_info = tasks_db[task_id]
        if task_info.status == TaskStatus.RUNNING:
            raise HTTPException(status_code=400, detail="‰ªªÂä°Ê≠£Âú®ËøêË°å‰∏≠")
        
        # Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ
        task_info.status = TaskStatus.RUNNING
        task_info.current_step = step
        task_info.updated_at = datetime.now()
        
        try:
            config = self.load_task_config(task_id)
            success = False
            
            # ‰ΩøÁî®StepProcessorÊâßË°åÂÖ∑‰ΩìÊ≠•È™§
            if step == TrainingStep.CONVERT_AUDIO:
                success = await self.step_processor.convert_audio(
                    config["INPUT_AUDIO"],
                    config["WORK_DIR"] + "/converted_wav"
                )
                # Êõ¥Êñ∞ÈÖçÁΩÆ‰∏≠ÁöÑËæìÂÖ•ÁõÆÂΩï
                if success:
                    config["INPUT_AUDIO"] = config["WORK_DIR"] + "/converted_wav"
                    self._save_task_config(task_id, config)
                    
            elif step == TrainingStep.SLICE_AUDIO:
                success = await self.step_processor.slice_audio(
                    config["INPUT_AUDIO"],
                    config["SLICED_DIR"],
                    **(params or {})
                )
                
            elif step == TrainingStep.DENOISE_AUDIO:
                success = await self.step_processor.denoise_audio(
                    config["SLICED_DIR"],
                    config["DENOISED_DIR"],
                    params.get("precision", "float16") if params else "float16"
                )
                
            elif step == TrainingStep.ASR_TRANSCRIBE:
                success = await self.step_processor.asr_transcribe(
                    config["DENOISED_DIR"],
                    config["ASR_OUTPUT"],
                    config["LANGUAGE"],
                    params.get("precision", "float16") if params else "float16"
                )
                
            elif step == TrainingStep.EXTRACT_TEXT_FEATURES:
                # ‰øÆÂ§çÔºöÁ°Æ‰øùASRËæìÂá∫ÊåáÂêëÂÖ∑‰ΩìÁöÑÊñá‰ª∂ËÄå‰∏çÊòØÁõÆÂΩï
                try:
                    asr_output = self._find_asr_output_file(config["ASR_OUTPUT"])
                    if asr_output != config["ASR_OUTPUT"]:
                        logger.info(f"‚úÖ ÊâæÂà∞ASRËæìÂá∫Êñá‰ª∂: {asr_output}")
                        # Êõ¥Êñ∞ÈÖçÁΩÆ
                        config["ASR_OUTPUT"] = asr_output
                        self._save_task_config(task_id, config)
                except FileNotFoundError as e:
                    logger.error(f"‚ùå ASRËæìÂá∫Êñá‰ª∂Êü•ÊâæÂ§±Ë¥•: {e}")
                    task_info.status = TaskStatus.FAILED
                    task_info.error_message = str(e)
                    return
                
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "1-get-text.py", env_vars, parallel_parts, gpu_ids
                )
                
                if success:
                    # ÂêàÂπ∂ÂàÜÁâáÊñá‰ª∂
                    await self.step_processor.merge_feature_files(
                        config["EXP_DIR"], "2-name2text-{}.txt", "2-name2text.txt", 
                        has_header=False, parallel_parts=parallel_parts
                    )
                    
            elif step == TrainingStep.EXTRACT_AUDIO_FEATURES:
                # ‰øÆÂ§çÔºöÁ°Æ‰øùASRËæìÂá∫ÊåáÂêëÂÖ∑‰ΩìÁöÑÊñá‰ª∂ËÄå‰∏çÊòØÁõÆÂΩï
                try:
                    asr_output = self._find_asr_output_file(config["ASR_OUTPUT"])
                    if asr_output != config["ASR_OUTPUT"]:
                        logger.info(f"‚úÖ ÊâæÂà∞ASRËæìÂá∫Êñá‰ª∂: {asr_output}")
                        # Êõ¥Êñ∞ÈÖçÁΩÆ
                        config["ASR_OUTPUT"] = asr_output
                        self._save_task_config(task_id, config)
                except FileNotFoundError as e:
                    logger.error(f"‚ùå ASRËæìÂá∫Êñá‰ª∂Êü•ÊâæÂ§±Ë¥•: {e}")
                    task_info.status = TaskStatus.FAILED
                    task_info.error_message = str(e)
                    return
                
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "2-get-hubert-wav32k.py", env_vars, parallel_parts, gpu_ids
                )
                
            elif step == TrainingStep.EXTRACT_SPEAKER_VECTORS:
                # ‰øÆÂ§çÔºöÁ°Æ‰øùASRËæìÂá∫ÊåáÂêëÂÖ∑‰ΩìÁöÑÊñá‰ª∂ËÄå‰∏çÊòØÁõÆÂΩï
                try:
                    asr_output = self._find_asr_output_file(config["ASR_OUTPUT"])
                    if asr_output != config["ASR_OUTPUT"]:
                        logger.info(f"‚úÖ ÊâæÂà∞ASRËæìÂá∫Êñá‰ª∂: {asr_output}")
                        # Êõ¥Êñ∞ÈÖçÁΩÆ
                        config["ASR_OUTPUT"] = asr_output
                        self._save_task_config(task_id, config)
                except FileNotFoundError as e:
                    logger.error(f"‚ùå ASRËæìÂá∫Êñá‰ª∂Êü•ÊâæÂ§±Ë¥•: {e}")
                    task_info.status = TaskStatus.FAILED
                    task_info.error_message = str(e)
                    return
                
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "2-get-sv.py", env_vars, parallel_parts, gpu_ids
                )
                
            elif step == TrainingStep.EXTRACT_SEMANTIC_FEATURES:
                # ‰øÆÂ§çÔºöÁ°Æ‰øùASRËæìÂá∫ÊåáÂêëÂÖ∑‰ΩìÁöÑÊñá‰ª∂ËÄå‰∏çÊòØÁõÆÂΩï
                try:
                    asr_output = self._find_asr_output_file(config["ASR_OUTPUT"])
                    if asr_output != config["ASR_OUTPUT"]:
                        logger.info(f"‚úÖ ÊâæÂà∞ASRËæìÂá∫Êñá‰ª∂: {asr_output}")
                        # Êõ¥Êñ∞ÈÖçÁΩÆ
                        config["ASR_OUTPUT"] = asr_output
                        self._save_task_config(task_id, config)
                except FileNotFoundError as e:
                    logger.error(f"‚ùå ASRËæìÂá∫Êñá‰ª∂Êü•ÊâæÂ§±Ë¥•: {e}")
                    task_info.status = TaskStatus.FAILED
                    task_info.error_message = str(e)
                    return
                
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "3-get-semantic.py", env_vars, parallel_parts, gpu_ids
                )
                
                if success:
                    # ÂêàÂπ∂ÂàÜÁâáÊñá‰ª∂
                    await self.step_processor.merge_feature_files(
                        config["EXP_DIR"], "6-name2semantic-{}.tsv", "6-name2semantic.tsv", 
                        has_header=True, parallel_parts=parallel_parts
                    )
                    
            elif step == TrainingStep.TRAIN_SOVITS:
                # ÁîüÊàêS2ÈÖçÁΩÆÊñá‰ª∂
                s2_config_path = config["WORK_DIR"] + "/config_s2.json"
                self.config_generator.generate_s2_config(config, s2_config_path)
                
                success = await self.step_processor.train_model(
                    "s2_train.py", s2_config_path
                )
                
            elif step == TrainingStep.TRAIN_GPT:
                # ÁîüÊàêS1ÈÖçÁΩÆÊñá‰ª∂
                s1_config_path = config["WORK_DIR"] + "/config_s1.yaml"
                self.config_generator.generate_s1_config(config, s1_config_path)
                
                env_vars = {"hz": "25hz"}
                success = await self.step_processor.train_model(
                    "s1_train.py", s1_config_path, env_vars
                )
                
            elif step == TrainingStep.TEST_INFERENCE:
                inference_params = params or {}
                inference_params.update({
                    "output_path": config["WORK_DIR"] + "/output",
                    "bert_path": config["BERT_DIR"],
                    "cnhubert_base_path": config["CNHUBERT_DIR"],
                    "gpu_number": config["GPU_ID"],
                    "is_half": True
                })
                
                success = await self.step_processor.test_inference(**inference_params)
                
            else:
                raise ValueError(f"‰∏çÊîØÊåÅÁöÑËÆ≠ÁªÉÊ≠•È™§: {step}")
            
            if success:
                task_info.status = TaskStatus.COMPLETED
                self._update_progress(task_id, step)
            else:
                task_info.status = TaskStatus.FAILED
                task_info.error_message = f"Ê≠•È™§ {step} ÊâßË°åÂ§±Ë¥•"
                
        except Exception as e:
            task_info.status = TaskStatus.FAILED
            task_info.error_message = str(e)
        finally:
            task_info.updated_at = datetime.now()
    
    def _save_task_config(self, task_id: str, config: Dict[str, Any]):
        """‰øùÂ≠ò‰ªªÂä°ÈÖçÁΩÆ"""
        config_file = self.get_task_dir(task_id) / "task_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def _find_asr_output_file(self, asr_output_path: str) -> str:
        """Êô∫ËÉΩÊü•ÊâæASRËæìÂá∫Êñá‰ª∂"""
        asr_path = Path(asr_output_path)
        
        if asr_path.is_file():
            # Â¶ÇÊûúÂ∑≤ÁªèÊòØÊñá‰ª∂ÔºåÁõ¥Êé•ËøîÂõû
            return str(asr_path)
        
        if asr_path.is_dir():
            # Â¶ÇÊûúÊòØÁõÆÂΩïÔºåÊåâ‰ºòÂÖàÁ∫ßÊü•ÊâæÊñá‰ª∂
            # ‰ºòÂÖàÁ∫ß1: .listÊñá‰ª∂ÔºàÊ†áÂáÜÊ†ºÂºèÔºâ
            list_files = list(asr_path.glob("*.list"))
            if list_files:
                return str(list_files[0])
            
            # ‰ºòÂÖàÁ∫ß2: .txtÊñá‰ª∂
            txt_files = list(asr_path.glob("*.txt"))
            if txt_files:
                return str(txt_files[0])
            
            # ‰ºòÂÖàÁ∫ß3: .tsvÊñá‰ª∂
            tsv_files = list(asr_path.glob("*.tsv"))
            if tsv_files:
                return str(tsv_files[0])
            
            # ‰ºòÂÖàÁ∫ß4: ‰ªª‰ΩïÂÖ∂‰ªñÊñá‰ª∂
            other_files = list(asr_path.glob("*"))
            if other_files:
                return str(other_files[0])
            
            # Â¶ÇÊûúÈÉΩÊâæ‰∏çÂà∞ÔºåÊäõÂá∫ÈîôËØØ
            raise FileNotFoundError(f"Âú®ASRËæìÂá∫ÁõÆÂΩï‰∏≠Êâæ‰∏çÂà∞ËΩ¨ÂΩïÊñá‰ª∂: {asr_output_path}")
        
        # Â¶ÇÊûúË∑ØÂæÑ‰∏çÂ≠òÂú®ÔºåÊäõÂá∫ÈîôËØØ
        raise FileNotFoundError(f"ASRËæìÂá∫Ë∑ØÂæÑ‰∏çÂ≠òÂú®: {asr_output_path}")
    

    def _build_step_env(self, config: Dict[str, Any]) -> Dict[str, str]:
        """ÊûÑÂª∫Ê≠•È™§ÊâßË°åÁéØÂ¢ÉÂèòÈáè"""
        env = os.environ.copy()
        env.update({
            "inp_text": config["ASR_OUTPUT"],
            "inp_wav_dir": config["DENOISED_DIR"],
            "exp_name": config["EXP_NAME"],
            "opt_dir": config["EXP_DIR"],
            "bert_pretrained_dir": config["BERT_DIR"],
            "cnhubert_base_dir": config["CNHUBERT_DIR"],
            "sv_path": config["PRETRAINED_SV"],
            "s2config_path": "GPT_SoVITS/configs/s2v2ProPlus.json",
            "is_half": "True",
            "BATCH_SIZE": str(config["BATCH_SIZE"]),
            "EPOCHS_S2": str(config["EPOCHS_S2"]),
            "S2_VERSION": "v2ProPlus",
            "_CUDA_VISIBLE_DEVICES": config["GPU_ID"]
        })
        return env
    
    def _update_progress(self, task_id: str, completed_step: TrainingStep):
        """Êõ¥Êñ∞‰ªªÂä°ËøõÂ∫¶"""
        if task_id not in tasks_db:
            return
        
        # ÂÆö‰πâÊ≠•È™§ÊùÉÈáç
        step_weights = {
            TrainingStep.CONVERT_AUDIO: 5,
            TrainingStep.SLICE_AUDIO: 10,
            TrainingStep.DENOISE_AUDIO: 10,
            TrainingStep.ASR_TRANSCRIBE: 15,
            TrainingStep.EXTRACT_TEXT_FEATURES: 10,
            TrainingStep.EXTRACT_AUDIO_FEATURES: 10,
            TrainingStep.EXTRACT_SPEAKER_VECTORS: 10,
            TrainingStep.EXTRACT_SEMANTIC_FEATURES: 10,
            TrainingStep.TRAIN_SOVITS: 15,
            TrainingStep.TRAIN_GPT: 15,
            TrainingStep.TEST_INFERENCE: 5
        }
        
        total_weight = sum(step_weights.values())
        completed_weight = sum(weight for step, weight in step_weights.items() 
                             if step.value <= completed_step.value)
        
        tasks_db[task_id].progress = (completed_weight / total_weight) * 100

# ÂàùÂßãÂåñÊúçÂä°
training_service = TrainingService()

# APIË∑ØÁî±
@app.post("/api/v1/task/create", response_model=TaskInfo)
async def create_task(request: TaskCreateRequest):
    """ÂàõÂª∫Êñ∞ÁöÑËÆ≠ÁªÉ‰ªªÂä°"""
    task_id = str(uuid.uuid4())
    
    # ÂàõÂª∫‰ªªÂä°‰ø°ÊÅØ
    task_info = TaskInfo(
        task_id=task_id,
        task_name=request.task_name,
        status=TaskStatus.CREATED,
        config=request.config,
        created_at=datetime.now(),
        updated_at=datetime.now()
    )
    
    # ‰øùÂ≠ò‰ªªÂä°
    tasks_db[task_id] = task_info
    
    # ÂàõÂª∫‰ªªÂä°ÁõÆÂΩïÂíåÈÖçÁΩÆÊñá‰ª∂
    training_service.create_task_config_file(task_id, request.config)
    
    return task_info

@app.get("/api/v1/task/{task_id}", response_model=TaskInfo)
async def get_task(task_id: str):
    """Ëé∑Âèñ‰ªªÂä°‰ø°ÊÅØ"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="‰ªªÂä°‰∏çÂ≠òÂú®")
    return tasks_db[task_id]

@app.get("/api/v1/tasks", response_model=List[TaskInfo])
async def list_tasks():
    """ÂàóÂá∫ÊâÄÊúâ‰ªªÂä°"""
    return list(tasks_db.values())

@app.post("/api/v1/task/{task_id}/step/{step}")
async def execute_step(task_id: str, step: TrainingStep, request: StepExecuteRequest, background_tasks: BackgroundTasks):
    """ÊâßË°åËÆ≠ÁªÉÊ≠•È™§"""
    background_tasks.add_task(training_service.execute_step, task_id, step, request.params)
    return {"message": f"Ê≠•È™§ {step} ÂºÄÂßãÊâßË°å", "task_id": task_id}

@app.post("/api/v1/task/{task_id}/cancel")
async def cancel_task(task_id: str):
    """ÂèñÊ∂à‰ªªÂä°"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="‰ªªÂä°‰∏çÂ≠òÂú®")
    
    # ÁªàÊ≠¢Ê≠£Âú®ËøêË°åÁöÑËøõÁ®ã
    if task_id in step_processes:
        process = step_processes[task_id]
        process.terminate()
        del step_processes[task_id]
    
    # Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ
    tasks_db[task_id].status = TaskStatus.CANCELLED
    tasks_db[task_id].updated_at = datetime.now()
    
    return {"message": "‰ªªÂä°Â∑≤ÂèñÊ∂à"}

@app.post("/api/v1/task/{task_id}/files/upload")
async def upload_file(task_id: str, file: UploadFile = File(...)):
    """‰∏ä‰º†ËÆ≠ÁªÉÈü≥È¢ëÊñá‰ª∂"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="‰ªªÂä°‰∏çÂ≠òÂú®")
    
    # Ëé∑Âèñ‰ªªÂä°ËæìÂÖ•ÁõÆÂΩï
    input_dir = training_service.get_task_input_dir(task_id)
    file_path = input_dir / file.filename
    
    # ‰øùÂ≠òÊñá‰ª∂
    with open(file_path, "wb") as f:
        content = await file.read()
        f.write(content)
    
    return {"message": "Êñá‰ª∂‰∏ä‰º†ÊàêÂäü", "filename": file.filename, "path": str(file_path)}

@app.get("/api/v1/task/{task_id}/files/download/{filename}")
async def download_file(task_id: str, filename: str):
    """‰∏ãËΩΩËÆ≠ÁªÉÁªìÊûúÊñá‰ª∂"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="‰ªªÂä°‰∏çÂ≠òÂú®")
    
    # Êü•ÊâæÊñá‰ª∂
    task_dir = training_service.get_task_dir(task_id)
    file_path = None
    
    # Âú®ÂêÑ‰∏™ÂèØËÉΩÁöÑÁõÆÂΩï‰∏≠Êü•ÊâæÊñá‰ª∂
    search_dirs = [
        task_dir / "output",
        task_dir / "experiments" / tasks_db[task_id].config.exp_name,
        task_dir
    ]
    
    for search_dir in search_dirs:
        candidate_path = search_dir / filename
        if candidate_path.exists():
            file_path = candidate_path
            break
    
    if not file_path:
        raise HTTPException(status_code=404, detail="Êñá‰ª∂‰∏çÂ≠òÂú®")
    
    return FileResponse(file_path, filename=filename)

@app.get("/api/v1/task/{task_id}/logs")
async def get_task_logs(task_id: str):
    """Ëé∑Âèñ‰ªªÂä°Êó•Âøó"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="‰ªªÂä°‰∏çÂ≠òÂú®")
    
    # ËØªÂèñÊó•ÂøóÊñá‰ª∂
    log_file = training_service.get_task_dir(task_id) / "training.log"
    if log_file.exists():
        with open(log_file, 'r', encoding='utf-8') as f:
            logs = f.read()
        return {"logs": logs}
    else:
        return {"logs": "ÊöÇÊó†Êó•Âøó"}

@app.delete("/api/v1/task/{task_id}")
async def delete_task(task_id: str):
    """Âà†Èô§‰ªªÂä°"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="‰ªªÂä°‰∏çÂ≠òÂú®")
    
    # ÂèñÊ∂àÊ≠£Âú®ËøêË°åÁöÑ‰ªªÂä°
    if tasks_db[task_id].status == TaskStatus.RUNNING:
        await cancel_task(task_id)
    
    # Âà†Èô§‰ªªÂä°ÁõÆÂΩï
    import shutil
    task_dir = training_service.get_task_dir(task_id)
    if task_dir.exists():
        shutil.rmtree(task_dir)
    
    # ‰ªéÊï∞ÊçÆÂ∫ì‰∏≠Âà†Èô§
    del tasks_db[task_id]
    
    return {"message": "‰ªªÂä°Â∑≤Âà†Èô§"}

@app.get("/")
async def root():
    """Ê†πË∑ØÂæÑ"""
    return {
        "message": "GPT-SoVITSËÆ≠ÁªÉÊúçÂä°API",
        "version": "1.0.0",
        "docs_url": "/docs"
    }

def parse_arguments():
    """Ëß£ÊûêÂëΩ‰ª§Ë°åÂèÇÊï∞"""
    parser = argparse.ArgumentParser(
        description="GPT-SoVITSËÆ≠ÁªÉÊúçÂä°API",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
‰ΩøÁî®Á§∫‰æã:
  python training_service.py                    # ‰ΩøÁî®ÈªòËÆ§Á´ØÂè£8000
  python training_service.py --port 8216       # ÊåáÂÆöÁ´ØÂè£8216
  python training_service.py -p 9000           # ‰ΩøÁî®Áü≠ÂèÇÊï∞ÊåáÂÆöÁ´ØÂè£
  python training_service.py --host 127.0.0.1  # ÊåáÂÆö‰∏ªÊú∫Âú∞ÂùÄ
  python training_service.py --config          # ÊòæÁ§∫ÂΩìÂâçÈÖçÁΩÆ
  python training_service.py --help            # ÊòæÁ§∫Â∏ÆÂä©‰ø°ÊÅØ
        """
    )
    
    parser.add_argument(
        "-p", "--port",
        type=int,
        default=None,
        help="ÊúçÂä°Á´ØÂè£Âè∑ (ÈªòËÆ§: ‰ªéÈÖçÁΩÆÊñá‰ª∂ËØªÂèñ)"
    )
    
    parser.add_argument(
        "-H", "--host",
        type=str,
        default=None,
        help="ÁªëÂÆö‰∏ªÊú∫Âú∞ÂùÄ (ÈªòËÆ§: ‰ªéÈÖçÁΩÆÊñá‰ª∂ËØªÂèñ)"
    )
    
    parser.add_argument(
        "--workers",
        type=int,
        default=None,
        help="Â∑•‰ΩúËøõÁ®ãÊï∞ (ÈªòËÆ§: ‰ªéÈÖçÁΩÆÊñá‰ª∂ËØªÂèñ)"
    )
    
    parser.add_argument(
        "--log-level",
        type=str,
        default=None,
        choices=["debug", "info", "warning", "error"],
        help="Êó•ÂøóÁ∫ßÂà´ (ÈªòËÆ§: ‰ªéÈÖçÁΩÆÊñá‰ª∂ËØªÂèñ)"
    )
    
    parser.add_argument(
        "--reload",
        action="store_true",
        help="ÂºÄÂèëÊ®°ÂºèÔºö‰ª£Á†ÅÂèòÊõ¥Êó∂Ëá™Âä®ÈáçËΩΩ"
    )
    
    parser.add_argument(
        "--config",
        action="store_true",
        help="ÊòæÁ§∫ÂΩìÂâçÈÖçÁΩÆ‰ø°ÊÅØ"
    )
    
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_arguments()
    
    # Â¶ÇÊûúÂè™ÊòØÊòæÁ§∫ÈÖçÁΩÆÔºåÂàôÊòæÁ§∫ÂêéÈÄÄÂá∫
    if args.config:
        from service_config import print_config
        print_config()
        exit(0)
    
    # ÂØºÂÖ•ÈÖçÁΩÆ
    from service_config import SERVICE_CONFIG
    
    # ‰ΩøÁî®ÂëΩ‰ª§Ë°åÂèÇÊï∞Ë¶ÜÁõñÈÖçÁΩÆÊñá‰ª∂ÔºåÂ¶ÇÊûúÊ≤°ÊúâÊåáÂÆöÂàô‰ΩøÁî®ÈÖçÁΩÆÊñá‰ª∂ÁöÑÂÄº
    host = args.host or SERVICE_CONFIG["host"]
    port = args.port or SERVICE_CONFIG["port"]
    workers = args.workers or SERVICE_CONFIG["workers"]
    log_level = args.log_level or SERVICE_CONFIG["log_level"]
    
    logger.info(f"üöÄ ÂêØÂä® GPT-SoVITS ËÆ≠ÁªÉÊúçÂä°API")
    logger.info(f"üìç ÊúçÂä°Âú∞ÂùÄ: http://{host}:{port}")
    logger.info(f"üìö APIÊñáÊ°£: http://{host}:{port}/docs")
    logger.info(f"üîß Â∑•‰ΩúËøõÁ®ã: {workers}")
    logger.info(f"üìù Êó•ÂøóÁ∫ßÂà´: {log_level}")
    logger.info(f"üîÑ Ëá™Âä®ÈáçËΩΩ: {'ÂºÄÂêØ' if args.reload else 'ÂÖ≥Èó≠'}")
    logger.info("=" * 50)
    
    uvicorn.run(
        app, 
        host=host, 
        port=port,
        workers=workers,
        log_level=log_level,
        reload=args.reload
    )
