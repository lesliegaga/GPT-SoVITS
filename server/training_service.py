#!/usr/bin/env python3
"""
GPT-SoVITSè®­ç»ƒæœåŠ¡API
æä¾›å®Œæ•´çš„è¯­éŸ³å…‹éš†è®­ç»ƒæµç¨‹APIæ¥å£
"""

import os
import sys
import json
import uuid
import asyncio
import subprocess
import argparse
import logging
import shutil
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path
from enum import Enum

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field
import uvicorn

# å¯¼å…¥æ­¥éª¤å¤„ç†å™¨å’Œé…ç½®
import os

# æ ¹æ®è¿è¡Œç¯å¢ƒé€‰æ‹©å¯¼å…¥æ–¹å¼
if os.getenv('GPT_SOVITS_SERVER_MODE') == 'standalone':
    # ç‹¬ç«‹è¿è¡Œæ¨¡å¼ï¼ˆä»serverç›®å½•ç›´æ¥è¿è¡Œï¼‰
    from training_steps import StepProcessor, ConfigGenerator
    from service_config import get_base_path, get_work_dir, get_model_paths
else:
    # åŒ…æ¨¡å¼ï¼ˆä»æ ¹ç›®å½•å¯¼å…¥ï¼‰
    from .training_steps import StepProcessor, ConfigGenerator
    from .service_config import get_base_path, get_work_dir, get_model_paths

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('training_service.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

def check_and_fix_nltk_cmudict():
    """æ£€æŸ¥å¹¶ä¿®å¤NLTK CMUè¯å…¸æ•°æ®åŒ…"""
    try:
        import nltk
        
        # å°è¯•ç›´æ¥æŸ¥æ‰¾CMUè¯å…¸
        try:
            nltk.data.find('corpora/cmudict.zip')
            logger.info("âœ… NLTK CMUè¯å…¸æ£€æŸ¥é€šè¿‡")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ NLTK CMUè¯å…¸æ£€æŸ¥å¤±è´¥: {e}")
        
        # å°è¯•æµ‹è¯•g2p_enæ¨¡å—
        try:
            from g2p_en import G2p
            g2p = G2p()
            g2p("test")  # ç®€å•æµ‹è¯•
            logger.info("âœ… g2p_enæ¨¡å—æµ‹è¯•é€šè¿‡")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ g2p_enæ¨¡å—æµ‹è¯•å¤±è´¥: {e}")
        
        # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œå°è¯•ä¿®å¤
        logger.info("ğŸ”§ å¼€å§‹ä¿®å¤NLTK CMUè¯å…¸...")
        
        # æŸ¥æ‰¾å¹¶å¤‡ä»½æŸåçš„æ–‡ä»¶
        for data_path in nltk.data.path:
            cmudict_path = Path(data_path) / "corpora" / "cmudict.zip"
            if cmudict_path.exists():
                try:
                    # å°è¯•æ‰“å¼€æ–‡ä»¶æ£€æŸ¥æ˜¯å¦æŸå
                    import zipfile
                    with zipfile.ZipFile(cmudict_path, 'r') as zf:
                        zf.testzip()
                    logger.info(f"âœ… CMUè¯å…¸æ–‡ä»¶å®Œå¥½: {cmudict_path}")
                except Exception:
                    # æ–‡ä»¶æŸåï¼Œè¿›è¡Œå¤‡ä»½
                    backup_path = cmudict_path.with_suffix('.zip.backup')
                    logger.info(f"ğŸ”„ å¤‡ä»½æŸåæ–‡ä»¶: {cmudict_path} -> {backup_path}")
                    shutil.move(cmudict_path, backup_path)
        
        # é‡æ–°ä¸‹è½½CMUè¯å…¸
        logger.info("ğŸ“¥ é‡æ–°ä¸‹è½½NLTK CMUè¯å…¸...")
        nltk.download('cmudict', force=True)
        
        # å†æ¬¡æµ‹è¯•
        try:
            from g2p_en import G2p
            g2p = G2p()
            g2p("test")
            logger.info("âœ… NLTK CMUè¯å…¸ä¿®å¤æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ NLTK CMUè¯å…¸ä¿®å¤å¤±è´¥: {e}")
            return False
            
    except ImportError:
        logger.warning("âš ï¸ NLTKæœªå®‰è£…ï¼Œè·³è¿‡æ£€æŸ¥")
        return True
    except Exception as e:
        logger.error(f"âŒ NLTKæ£€æŸ¥å¼‚å¸¸: {e}")
        return False

# æ–°å¢ï¼šæ£€æŸ¥å¹¶ä¿®å¤NLTKè‹±æ–‡è¯æ€§æ ‡æ³¨å™¨
def check_and_fix_nltk_tagger():
    """æ£€æŸ¥å¹¶ä¿®å¤NLTK averaged_perceptron_tagger_eng æ•°æ®åŒ…"""
    try:
        import nltk

        # å°è¯•ç›´æ¥æŸ¥æ‰¾æ ‡æ³¨å™¨
        try:
            nltk.data.find('taggers/averaged_perceptron_tagger_eng')
            logger.info("âœ… NLTK averaged_perceptron_tagger_eng æ£€æŸ¥é€šè¿‡")
            return True
        except Exception as e:
            logger.warning(f"âš ï¸ æ ‡æ³¨å™¨æ£€æŸ¥å¤±è´¥: {e}")

        # ä¸‹è½½æ ‡æ³¨å™¨
        logger.info("ğŸ“¥ æ­£åœ¨ä¸‹è½½ NLTK averaged_perceptron_tagger_eng â€¦")
        nltk.download('averaged_perceptron_tagger_eng', force=True)

        # å†æ¬¡ç¡®è®¤
        try:
            nltk.data.find('taggers/averaged_perceptron_tagger_eng')
            logger.info("âœ… NLTK averaged_perceptron_tagger_eng ä¿®å¤æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ æ ‡æ³¨å™¨ä¿®å¤å¤±è´¥: {e}")
            return False

    except ImportError:
        logger.warning("âš ï¸ NLTKæœªå®‰è£…ï¼Œè·³è¿‡æ ‡æ³¨å™¨æ£€æŸ¥")
        return True
    except Exception as e:
        logger.error(f"âŒ NLTKæ ‡æ³¨å™¨æ£€æŸ¥å¼‚å¸¸: {e}")
        return False

# å¤„ç†çŠ¶æ€æšä¸¾
class ProcessingStatus(str, Enum):
    PENDING = "pending"      # ç­‰å¾…å¤„ç†
    RUNNING = "running"      # æ­£åœ¨å¤„ç†
    COMPLETED = "completed"  # å¤„ç†å®Œæˆ
    FAILED = "failed"        # å¤„ç†å¤±è´¥
    CANCELLED = "cancelled"  # å·²å–æ¶ˆ

# éŸ³é¢‘å¤„ç†æ­¥éª¤æšä¸¾
class AudioProcessingStep(str, Enum):
    CONVERT_AUDIO = "convert_audio"
    SLICE_AUDIO = "slice_audio"
    DENOISE_AUDIO = "denoise_audio"
    ASR_TRANSCRIBE = "asr_transcribe"

# è®­ç»ƒæ­¥éª¤æšä¸¾
class TrainingStep(str, Enum):
    EXTRACT_TEXT_FEATURES = "extract_text_features"
    EXTRACT_AUDIO_FEATURES = "extract_audio_features"
    EXTRACT_SPEAKER_VECTORS = "extract_speaker_vectors"
    EXTRACT_SEMANTIC_FEATURES = "extract_semantic_features"
    TRAIN_SOVITS = "train_sovits"
    TRAIN_GPT = "train_gpt"

# æ¨ç†æ­¥éª¤æšä¸¾
class InferenceStep(str, Enum):
    TEST_INFERENCE = "test_inference"

# è§’è‰²é…ç½®æ¨¡å‹
class CharacterConfig(BaseModel):
    character_name: str = Field(description="è§’è‰²åç§°")
    language: str = Field(default="zh", description="è¯­è¨€è®¾ç½®")
    batch_size: int = Field(default=16, description="æ‰¹æ¬¡å¤§å°")
    epochs_s2: int = Field(default=50, description="SoVITSè®­ç»ƒè½®æ•°")
    epochs_s1: int = Field(default=15, description="GPTè®­ç»ƒè½®æ•°")
    gpu_id: str = Field(default=os.environ.get("CUDA_VISIBLE_DEVICES", "0"), description="GPUè®¾å¤‡ID")
    enable_denoise: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨é™å™ª")

# è§’è‰²åˆ›å»ºè¯·æ±‚
class CharacterCreateRequest(BaseModel):
    character_name: str = Field(description="è§’è‰²åç§°")
    config: CharacterConfig = Field(description="è§’è‰²é…ç½®")

# è§’è‰²é‡å‘½åè¯·æ±‚
class CharacterRenameRequest(BaseModel):
    new_name: str = Field(description="æ–°è§’è‰²åç§°")

# è§’è‰²ä¿¡æ¯æ¨¡å‹
class CharacterInfo(BaseModel):
    character_name: str
    config: CharacterConfig
    created_at: datetime
    updated_at: datetime
    audio_count: int = 0
    audio_processing_status: ProcessingStatus = ProcessingStatus.PENDING
    training_status: ProcessingStatus = ProcessingStatus.PENDING
    model_exists: bool = False
    is_default: bool = False

# éŸ³é¢‘å¤„ç†ä¿¡æ¯æ¨¡å‹
class AudioProcessingInfo(BaseModel):
    character_name: str
    status: ProcessingStatus
    current_step: Optional[str] = None
    progress: float = 0.0
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None
    processed_audio_count: int = 0

# è®­ç»ƒä¿¡æ¯æ¨¡å‹
class TrainingInfo(BaseModel):
    character_name: str
    status: ProcessingStatus
    current_step: Optional[str] = None
    progress: float = 0.0
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None
    gpt_model_path: Optional[str] = None
    sovits_model_path: Optional[str] = None

# æ¨ç†è¯·æ±‚æ¨¡å‹
class InferenceRequest(BaseModel):
    character_name: Optional[str] = Field(default=None, description="è§’è‰²åç§°ï¼Œä¸ºç©ºåˆ™ä½¿ç”¨é»˜è®¤è§’è‰²")
    target_text: str = Field(description="ç›®æ ‡æ–‡æœ¬")
    ref_audio: Optional[str] = Field(default=None, description="å‚è€ƒéŸ³é¢‘è·¯å¾„")
    ref_text: Optional[str] = Field(default=None, description="å‚è€ƒæ–‡æœ¬")
    ref_language: str = Field(default="ä¸­æ–‡", description="å‚è€ƒè¯­è¨€")
    target_language: str = Field(default="ä¸­æ–‡", description="ç›®æ ‡è¯­è¨€")
    output_name: Optional[str] = Field(default=None, description="è¾“å‡ºæ–‡ä»¶å")

# æ¨ç†ä¿¡æ¯æ¨¡å‹
class InferenceInfo(BaseModel):
    inference_id: str
    character_name: str
    target_text: str
    status: ProcessingStatus
    created_at: datetime
    completed_at: Optional[datetime] = None
    output_path: Optional[str] = None
    error_message: Optional[str] = None

# æ­¥éª¤æ‰§è¡Œè¯·æ±‚æ¨¡å‹
class StepExecuteRequest(BaseModel):
    params: Optional[Dict[str, Any]] = Field(default_factory=dict, description="æ­¥éª¤ç‰¹å®šå‚æ•°")

# å…¨å±€æ•°æ®å­˜å‚¨
characters_db: Dict[str, CharacterInfo] = {}
audio_processing_db: Dict[str, AudioProcessingInfo] = {}
training_db: Dict[str, TrainingInfo] = {}
inference_db: Dict[str, InferenceInfo] = {}
step_processes: Dict[str, subprocess.Popen] = {}
default_character: Optional[str] = None

# FastAPIåº”ç”¨
app = FastAPI(
    title="GPT-SoVITSè®­ç»ƒæœåŠ¡",
    description="æä¾›å®Œæ•´çš„è¯­éŸ³å…‹éš†è®­ç»ƒæµç¨‹APIæ¥å£",
    version="1.0.0"
)

class CharacterBasedTrainingService:
    """åŸºäºè§’è‰²çš„è®­ç»ƒæœåŠ¡æ ¸å¿ƒç±»"""
    
    def __init__(self):
        # ä½¿ç”¨é…ç½®æ–‡ä»¶è·å–è·¯å¾„
        self.base_dir = get_base_path()
        self.work_dir = get_work_dir()
        
        self.step_processor = StepProcessor(str(self.base_dir))
        self.config_generator = ConfigGenerator(str(self.base_dir))
        
        # åˆ›å»ºè§’è‰²ç›®å½•
        self.characters_dir = self.work_dir / "characters"
        self.characters_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæ¨ç†è¾“å‡ºç›®å½•
        self.inference_output_dir = self.work_dir / "inference_output"
        self.inference_output_dir.mkdir(exist_ok=True)
        
        # æ£€æŸ¥å¹¶ä¿®å¤NLTK CMUè¯å…¸
        logger.info("ğŸ” æ£€æŸ¥NLTK CMUè¯å…¸...")
        check_and_fix_nltk_cmudict()
        # æ£€æŸ¥å¹¶ä¿®å¤NLTKè‹±æ–‡è¯æ€§æ ‡æ³¨å™¨
        logger.info("ğŸ” æ£€æŸ¥NLTK averaged_perceptron_tagger_eng â€¦")
        check_and_fix_nltk_tagger()
        
        # åŠ è½½ç°æœ‰è§’è‰²å’Œé»˜è®¤è§’è‰²è®¾ç½®
        self._load_existing_characters()
        self._load_default_character()
        
        logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"   åŸºç¡€ç›®å½•: {self.base_dir}")
        logger.info(f"   å·¥ä½œç›®å½•: {self.work_dir}")
        logger.info(f"   è§’è‰²ç›®å½•: {self.characters_dir}")
        logger.info(f"   æ¨ç†è¾“å‡ºç›®å½•: {self.inference_output_dir}")
    
    # ==================== è§’è‰²ç®¡ç† ====================
    
    def create_character(self, character_name: str, config: CharacterConfig) -> CharacterInfo:
        """åˆ›å»ºæ–°è§’è‰²"""
        if character_name in characters_db:
            raise ValueError(f"è§’è‰²å·²å­˜åœ¨: {character_name}")
        
        # éªŒè¯è§’è‰²åç§°ï¼ˆé¿å…ç‰¹æ®Šå­—ç¬¦ï¼‰
        if not character_name.replace('_', '').replace('-', '').isalnum():
            raise ValueError("è§’è‰²åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦")
        
        # åˆ›å»ºè§’è‰²ç›®å½•ç»“æ„
        character_dir = self.get_character_dir(character_name)
        character_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (character_dir / "raw_audio").mkdir(exist_ok=True)
        (character_dir / "converted_audio").mkdir(exist_ok=True)
        (character_dir / "sliced_audio").mkdir(exist_ok=True)
        (character_dir / "denoised_audio").mkdir(exist_ok=True)
        (character_dir / "transcripts").mkdir(exist_ok=True)
        (character_dir / "experiments").mkdir(exist_ok=True)
        (character_dir / "models").mkdir(exist_ok=True)
        
        # åˆ›å»ºè§’è‰²ä¿¡æ¯
        character_info = CharacterInfo(
            character_name=character_name,
            config=config,
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        characters_db[character_name] = character_info
        
        # ä¿å­˜è§’è‰²é…ç½®æ–‡ä»¶
        self._save_character_config(character_name, character_info)
        
        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªè§’è‰²ï¼Œè®¾ç½®ä¸ºé»˜è®¤è§’è‰²
        global default_character
        if default_character is None:
            default_character = character_name
            character_info.is_default = True
            self._save_default_character()
        
        logger.info(f"âœ… è§’è‰²åˆ›å»ºæˆåŠŸ: {character_name}")
        return character_info
    
    def rename_character(self, old_name: str, new_name: str) -> CharacterInfo:
        """é‡å‘½åè§’è‰²"""
        if old_name not in characters_db:
            raise ValueError(f"è§’è‰²ä¸å­˜åœ¨: {old_name}")
        
        if new_name in characters_db:
            raise ValueError(f"æ–°è§’è‰²åç§°å·²å­˜åœ¨: {new_name}")
        
        # éªŒè¯æ–°è§’è‰²åç§°
        if not new_name.replace('_', '').replace('-', '').isalnum():
            raise ValueError("è§’è‰²åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦")
        
        # é‡å‘½åç›®å½•
        old_dir = self.get_character_dir(old_name)
        new_dir = self.get_character_dir(new_name)
        
        if old_dir.exists():
            shutil.move(str(old_dir), str(new_dir))
        
        # æ›´æ–°æ•°æ®åº“
        character_info = characters_db[old_name]
        character_info.character_name = new_name
        character_info.config.character_name = new_name
        character_info.updated_at = datetime.now()
        
        characters_db[new_name] = character_info
        del characters_db[old_name]
        
        # æ›´æ–°éŸ³é¢‘å¤„ç†å’Œè®­ç»ƒä¿¡æ¯
        if old_name in audio_processing_db:
            audio_processing_db[old_name].character_name = new_name
            audio_processing_db[new_name] = audio_processing_db[old_name]
            del audio_processing_db[old_name]
        
        if old_name in training_db:
            training_db[old_name].character_name = new_name
            training_db[new_name] = training_db[old_name]
            del training_db[old_name]
        
        # æ›´æ–°é»˜è®¤è§’è‰²
        global default_character
        if default_character == old_name:
            default_character = new_name
            character_info.is_default = True
            self._save_default_character()
        
        # ä¿å­˜é…ç½®
        self._save_character_config(new_name, character_info)
        
        logger.info(f"âœ… è§’è‰²é‡å‘½åæˆåŠŸ: {old_name} -> {new_name}")
        return character_info
    
    def delete_character(self, character_name: str) -> bool:
        """åˆ é™¤è§’è‰²"""
        if character_name not in characters_db:
            raise ValueError(f"è§’è‰²ä¸å­˜åœ¨: {character_name}")
        
        # åˆ é™¤ç›®å½•
        character_dir = self.get_character_dir(character_name)
        if character_dir.exists():
            shutil.rmtree(character_dir)
        
        # åˆ é™¤æ•°æ®åº“è®°å½•
        del characters_db[character_name]
        
        if character_name in audio_processing_db:
            del audio_processing_db[character_name]
        
        if character_name in training_db:
            del training_db[character_name]
        
        # æ›´æ–°é»˜è®¤è§’è‰²
        global default_character
        if default_character == character_name:
            # é€‰æ‹©å¦ä¸€ä¸ªè§’è‰²ä½œä¸ºé»˜è®¤è§’è‰²
            remaining_characters = list(characters_db.keys())
            if remaining_characters:
                default_character = remaining_characters[0]
                characters_db[default_character].is_default = True
                self._save_default_character()
            else:
                default_character = None
                # åˆ é™¤é»˜è®¤è§’è‰²é…ç½®æ–‡ä»¶
                default_file = self.work_dir / "default_character.txt"
                if default_file.exists():
                    default_file.unlink()
        
        logger.info(f"âœ… è§’è‰²åˆ é™¤æˆåŠŸ: {character_name}")
        return True
    
    def set_default_character(self, character_name: str) -> bool:
        """è®¾ç½®é»˜è®¤è§’è‰²"""
        if character_name not in characters_db:
            raise ValueError(f"è§’è‰²ä¸å­˜åœ¨: {character_name}")
        
        global default_character
        
        # æ¸…é™¤æ—§çš„é»˜è®¤æ ‡è®°
        if default_character and default_character in characters_db:
            characters_db[default_character].is_default = False
        
        # è®¾ç½®æ–°çš„é»˜è®¤è§’è‰²
        default_character = character_name
        characters_db[character_name].is_default = True
        
        # ä¿å­˜é…ç½®
        self._save_default_character()
        
        logger.info(f"âœ… é»˜è®¤è§’è‰²è®¾ç½®ä¸º: {character_name}")
        return True
    
    def get_default_character(self) -> Optional[str]:
        """è·å–é»˜è®¤è§’è‰²"""
        return default_character
    
    def list_characters(self) -> List[CharacterInfo]:
        """åˆ—å‡ºæ‰€æœ‰è§’è‰²"""
        return list(characters_db.values())
    
    def get_character(self, character_name: str) -> CharacterInfo:
        """è·å–è§’è‰²ä¿¡æ¯"""
        if character_name not in characters_db:
            raise ValueError(f"è§’è‰²ä¸å­˜åœ¨: {character_name}")
        return characters_db[character_name]
    
    # ==================== ç›®å½•ç®¡ç† ====================
    
    def get_character_dir(self, character_name: str) -> Path:
        """è·å–è§’è‰²ç›®å½•"""
        return self.characters_dir / character_name
    
    def get_character_raw_audio_dir(self, character_name: str) -> Path:
        """è·å–è§’è‰²åŸå§‹éŸ³é¢‘ç›®å½•"""
        return self.get_character_dir(character_name) / "raw_audio"
    
    def get_character_converted_audio_dir(self, character_name: str) -> Path:
        """è·å–è§’è‰²è½¬æ¢åéŸ³é¢‘ç›®å½•"""
        return self.get_character_dir(character_name) / "converted_audio"
    
    def get_character_sliced_audio_dir(self, character_name: str) -> Path:
        """è·å–è§’è‰²åˆ‡ç‰‡éŸ³é¢‘ç›®å½•"""
        return self.get_character_dir(character_name) / "sliced_audio"
    
    def get_character_denoised_audio_dir(self, character_name: str) -> Path:
        """è·å–è§’è‰²é™å™ªéŸ³é¢‘ç›®å½•"""
        return self.get_character_dir(character_name) / "denoised_audio"
    
    def get_character_transcripts_dir(self, character_name: str) -> Path:
        """è·å–è§’è‰²è½¬å½•ç›®å½•"""
        return self.get_character_dir(character_name) / "transcripts"
    
    def get_character_experiments_dir(self, character_name: str) -> Path:
        """è·å–è§’è‰²å®éªŒç›®å½•"""
        exp_dir = self.get_character_dir(character_name) / "experiments" / character_name
        exp_dir.mkdir(parents=True, exist_ok=True)
        return exp_dir
    
    def get_character_models_dir(self, character_name: str) -> Path:
        """è·å–è§’è‰²æ¨¡å‹ç›®å½•"""
        return self.get_character_dir(character_name) / "models"
    
    # ==================== éŸ³é¢‘å¤„ç†ç®¡ç† ====================
    
    def get_audio_count(self, character_name: str) -> int:
        """è·å–è§’è‰²éŸ³é¢‘æ•°é‡"""
        raw_audio_dir = self.get_character_raw_audio_dir(character_name)
        if not raw_audio_dir.exists():
            return 0
        
        audio_files = []
        for ext in ['wav', 'mp3', 'm4a', 'flac', 'aac']:
            audio_files.extend(raw_audio_dir.glob(f"*.{ext}"))
        
        return len(audio_files)
    
    def update_character_audio_count(self, character_name: str):
        """æ›´æ–°è§’è‰²éŸ³é¢‘æ•°é‡"""
        if character_name in characters_db:
            characters_db[character_name].audio_count = self.get_audio_count(character_name)
            characters_db[character_name].updated_at = datetime.now()
    
    async def start_audio_processing(self, character_name: str, steps: List[AudioProcessingStep] = None) -> AudioProcessingInfo:
        """å¼€å§‹éŸ³é¢‘å¤„ç†"""
        if character_name not in characters_db:
            raise ValueError(f"è§’è‰²ä¸å­˜åœ¨: {character_name}")
        
        if steps is None:
            steps = [
                AudioProcessingStep.CONVERT_AUDIO,
                AudioProcessingStep.SLICE_AUDIO,
                AudioProcessingStep.DENOISE_AUDIO,
                AudioProcessingStep.ASR_TRANSCRIBE
            ]
            
            # å¦‚æœç¦ç”¨é™å™ªï¼Œç§»é™¤é™å™ªæ­¥éª¤
            if not characters_db[character_name].config.enable_denoise:
                steps.remove(AudioProcessingStep.DENOISE_AUDIO)
        
        # åˆ›å»ºéŸ³é¢‘å¤„ç†ä¿¡æ¯
        processing_info = AudioProcessingInfo(
            character_name=character_name,
            status=ProcessingStatus.RUNNING,
            started_at=datetime.now()
        )
        
        audio_processing_db[character_name] = processing_info
        characters_db[character_name].audio_processing_status = ProcessingStatus.RUNNING
        
        # å¯åŠ¨å¼‚æ­¥å¤„ç†
        asyncio.create_task(self._execute_audio_processing(character_name, steps))
        
        return processing_info
    
    async def _execute_audio_processing(self, character_name: str, steps: List[AudioProcessingStep]):
        """æ‰§è¡ŒéŸ³é¢‘å¤„ç†æ­¥éª¤"""
        processing_info = audio_processing_db[character_name]
        
        try:
            for i, step in enumerate(steps):
                processing_info.current_step = step.value
                processing_info.progress = (i / len(steps)) * 100
                
                logger.info(f"å¼€å§‹æ‰§è¡Œ {character_name} çš„éŸ³é¢‘å¤„ç†æ­¥éª¤: {step.value}")
                
                success = await self._execute_audio_processing_step(character_name, step)
                
                if not success:
                    processing_info.status = ProcessingStatus.FAILED
                    processing_info.error_message = f"æ­¥éª¤ {step.value} å¤±è´¥"
                    characters_db[character_name].audio_processing_status = ProcessingStatus.FAILED
                    return
            
            # æ‰€æœ‰æ­¥éª¤å®Œæˆ
            processing_info.status = ProcessingStatus.COMPLETED
            processing_info.progress = 100.0
            processing_info.completed_at = datetime.now()
            processing_info.processed_audio_count = self.get_processed_audio_count(character_name)
            
            characters_db[character_name].audio_processing_status = ProcessingStatus.COMPLETED
            
            logger.info(f"âœ… {character_name} éŸ³é¢‘å¤„ç†å®Œæˆ")
            
        except Exception as e:
            processing_info.status = ProcessingStatus.FAILED
            processing_info.error_message = str(e)
            characters_db[character_name].audio_processing_status = ProcessingStatus.FAILED
            logger.error(f"âŒ {character_name} éŸ³é¢‘å¤„ç†å¤±è´¥: {e}")
    
    async def _execute_audio_processing_step(self, character_name: str, step: AudioProcessingStep) -> bool:
        """æ‰§è¡Œå•ä¸ªéŸ³é¢‘å¤„ç†æ­¥éª¤"""
        try:
            if step == AudioProcessingStep.CONVERT_AUDIO:
                input_dir = str(self.get_character_raw_audio_dir(character_name))
                output_dir = str(self.get_character_converted_audio_dir(character_name))
                return await self.step_processor.convert_audio(input_dir, output_dir)
                
            elif step == AudioProcessingStep.SLICE_AUDIO:
                input_dir = str(self.get_character_converted_audio_dir(character_name))
                output_dir = str(self.get_character_sliced_audio_dir(character_name))
                return await self.step_processor.slice_audio(input_dir, output_dir)
                
            elif step == AudioProcessingStep.DENOISE_AUDIO:
                input_dir = str(self.get_character_sliced_audio_dir(character_name))
                output_dir = str(self.get_character_denoised_audio_dir(character_name))
                return await self.step_processor.denoise_audio(input_dir, output_dir)
                
            elif step == AudioProcessingStep.ASR_TRANSCRIBE:
                if characters_db[character_name].config.enable_denoise:
                    input_dir = str(self.get_character_denoised_audio_dir(character_name))
                else:
                    input_dir = str(self.get_character_sliced_audio_dir(character_name))
                    
                output_dir = str(self.get_character_transcripts_dir(character_name))
                language = characters_db[character_name].config.language
                return await self.step_processor.asr_transcribe(input_dir, output_dir, language)
            
            return False
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘å¤„ç†æ­¥éª¤ {step.value} å¤±è´¥: {e}")
            return False
    
    def get_processed_audio_count(self, character_name: str) -> int:
        """è·å–å·²å¤„ç†éŸ³é¢‘æ•°é‡"""
        if characters_db[character_name].config.enable_denoise:
            audio_dir = self.get_character_denoised_audio_dir(character_name)
        else:
            audio_dir = self.get_character_sliced_audio_dir(character_name)
            
        if not audio_dir.exists():
            return 0
            
        audio_files = list(audio_dir.glob("*.wav"))
        return len(audio_files)
    
    # ==================== è®­ç»ƒç®¡ç† ====================
    
    async def start_training(self, character_name: str, steps: List[TrainingStep] = None) -> TrainingInfo:
        """å¼€å§‹è®­ç»ƒ"""
        if character_name not in characters_db:
            raise ValueError(f"è§’è‰²ä¸å­˜åœ¨: {character_name}")
        
        # æ£€æŸ¥éŸ³é¢‘å¤„ç†æ˜¯å¦å®Œæˆ
        if characters_db[character_name].audio_processing_status != ProcessingStatus.COMPLETED:
            raise ValueError(f"è§’è‰² {character_name} çš„éŸ³é¢‘å¤„ç†å°šæœªå®Œæˆï¼Œæ— æ³•å¼€å§‹è®­ç»ƒ")
        
        if steps is None:
            steps = [
                TrainingStep.EXTRACT_TEXT_FEATURES,
                TrainingStep.EXTRACT_AUDIO_FEATURES,
                TrainingStep.EXTRACT_SPEAKER_VECTORS,
                TrainingStep.EXTRACT_SEMANTIC_FEATURES,
                TrainingStep.TRAIN_SOVITS,
                TrainingStep.TRAIN_GPT
            ]
        
        # åˆ›å»ºè®­ç»ƒä¿¡æ¯
        training_info = TrainingInfo(
            character_name=character_name,
            status=ProcessingStatus.RUNNING,
            started_at=datetime.now()
        )
        
        training_db[character_name] = training_info
        characters_db[character_name].training_status = ProcessingStatus.RUNNING
        
        # å¯åŠ¨å¼‚æ­¥è®­ç»ƒ
        asyncio.create_task(self._execute_training(character_name, steps))
        
        return training_info
    
    async def _execute_training(self, character_name: str, steps: List[TrainingStep]):
        """æ‰§è¡Œè®­ç»ƒæ­¥éª¤"""
        training_info = training_db[character_name]
        
        try:
            for i, step in enumerate(steps):
                training_info.current_step = step.value
                training_info.progress = (i / len(steps)) * 100
                
                logger.info(f"å¼€å§‹æ‰§è¡Œ {character_name} çš„è®­ç»ƒæ­¥éª¤: {step.value}")
                
                success = await self._execute_training_step(character_name, step)
                
                if not success:
                    training_info.status = ProcessingStatus.FAILED
                    training_info.error_message = f"æ­¥éª¤ {step.value} å¤±è´¥"
                    characters_db[character_name].training_status = ProcessingStatus.FAILED
                    return
            
            # æ‰€æœ‰æ­¥éª¤å®Œæˆ
            training_info.status = ProcessingStatus.COMPLETED
            training_info.progress = 100.0
            training_info.completed_at = datetime.now()
            
            # æŸ¥æ‰¾ç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶
            self._find_trained_models(character_name)
            # åŒæ­¥æ¨¡å‹åˆ°è§’è‰²ç›®å½•
            self._sync_character_models_dir(character_name)
            
            characters_db[character_name].training_status = ProcessingStatus.COMPLETED
            characters_db[character_name].model_exists = True
            
            logger.info(f"âœ… {character_name} è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            training_info.status = ProcessingStatus.FAILED
            training_info.error_message = str(e)
            characters_db[character_name].training_status = ProcessingStatus.FAILED
            logger.error(f"âŒ {character_name} è®­ç»ƒå¤±è´¥: {e}")
    
    async def _execute_training_step(self, character_name: str, step: TrainingStep) -> bool:
        """æ‰§è¡Œå•ä¸ªè®­ç»ƒæ­¥éª¤"""
        try:
            config = self._build_training_config(character_name)
            
            if step == TrainingStep.EXTRACT_TEXT_FEATURES:
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "1-get-text.py", env_vars, parallel_parts, gpu_ids
                )
                
                if success:
                    await self.step_processor.merge_feature_files(
                        config["EXP_DIR"], "2-name2text-{}.txt", "2-name2text.txt", 
                        has_header=False, parallel_parts=parallel_parts
                    )
                
                return success
                
            elif step == TrainingStep.EXTRACT_AUDIO_FEATURES:
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                return await self.step_processor.extract_features(
                    "2-get-hubert-wav32k.py", env_vars, parallel_parts, gpu_ids
                )
                
            elif step == TrainingStep.EXTRACT_SPEAKER_VECTORS:
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                return await self.step_processor.extract_features(
                    "2-get-sv.py", env_vars, parallel_parts, gpu_ids
                )
                
            elif step == TrainingStep.EXTRACT_SEMANTIC_FEATURES:
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "3-get-semantic.py", env_vars, parallel_parts, gpu_ids
                )
                
                if success:
                    await self.step_processor.merge_feature_files(
                        config["EXP_DIR"], "6-name2semantic-{}.tsv", "6-name2semantic.tsv", 
                        has_header=True, parallel_parts=parallel_parts
                    )
                
                return success
                
            elif step == TrainingStep.TRAIN_SOVITS:
                s2_config_path = str(self.get_character_dir(character_name) / "config_s2.json")
                self.config_generator.generate_s2_config(config, s2_config_path)
                return await self.step_processor.train_model("s2_train.py", s2_config_path)
                
            elif step == TrainingStep.TRAIN_GPT:
                s1_config_path = str(self.get_character_dir(character_name) / "config_s1.yaml")
                self.config_generator.generate_s1_config(config, s1_config_path)
                env_vars = {"hz": "25hz"}
                return await self.step_processor.train_model("s1_train.py", s1_config_path, env_vars)
            
            return False
            
        except Exception as e:
            logger.error(f"è®­ç»ƒæ­¥éª¤ {step.value} å¤±è´¥: {e}")
            return False
    
    # ==================== æ¨ç†ç®¡ç† ====================
    
    async def start_inference(self, request: InferenceRequest) -> InferenceInfo:
        """å¼€å§‹æ¨ç†"""
        # ç¡®å®šä½¿ç”¨çš„è§’è‰²
        character_name = request.character_name or default_character
        
        if not character_name:
            raise ValueError("æœªæŒ‡å®šè§’è‰²ä¸”æ— é»˜è®¤è§’è‰²")
        
        if character_name not in characters_db:
            raise ValueError(f"è§’è‰²ä¸å­˜åœ¨: {character_name}")
        
        if not characters_db[character_name].model_exists:
            raise ValueError(f"è§’è‰² {character_name} çš„æ¨¡å‹å°šæœªè®­ç»ƒå®Œæˆ")
        
        # åˆ›å»ºæ¨ç†ä¿¡æ¯
        inference_id = str(uuid.uuid4())
        inference_info = InferenceInfo(
            inference_id=inference_id,
            character_name=character_name,
            target_text=request.target_text,
            status=ProcessingStatus.RUNNING,
            created_at=datetime.now()
        )
        
        inference_db[inference_id] = inference_info
        
        # å¯åŠ¨å¼‚æ­¥æ¨ç†
        asyncio.create_task(self._execute_inference(inference_id, request))
        
        return inference_info
    
    async def _execute_inference(self, inference_id: str, request: InferenceRequest):
        """æ‰§è¡Œæ¨ç†"""
        inference_info = inference_db[inference_id]
        character_name = inference_info.character_name
        
        try:
            # æ¨ç†å‰å†æ¬¡æ£€æŸ¥NLTK CMUè¯å…¸ï¼ˆé˜²æ­¢è¿è¡Œæ—¶é—®é¢˜ï¼‰
            if not check_and_fix_nltk_cmudict():
                raise ValueError("NLTK CMUè¯å…¸æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ¨ç†")
            # æ¨ç†å‰æ£€æŸ¥è‹±æ–‡è¯æ€§æ ‡æ³¨å™¨
            if not check_and_fix_nltk_tagger():
                raise ValueError("NLTK averaged_perceptron_tagger_eng æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œæ¨ç†")
            
            # æ„å»ºæ¨ç†å‚æ•°
            inference_params = await self._build_inference_params(character_name, request)
            
            # æ‰§è¡Œæ¨ç†
            success = await self.step_processor.test_inference(**inference_params)
            
            if success:
                inference_info.status = ProcessingStatus.COMPLETED
                inference_info.completed_at = datetime.now()
                # è¾“å‡ºè·¯å¾„åº”è¯¥æ˜¯åŒ…å«output.wavçš„å®Œæ•´æ–‡ä»¶è·¯å¾„
                output_dir = inference_params.get("output_path")
                output_file = Path(output_dir) / "output.wav"
                inference_info.output_path = str(output_file)
                logger.info(f"âœ… æ¨ç†å®Œæˆ: {inference_id}")
                logger.info(f"   è¾“å‡ºæ–‡ä»¶: {inference_info.output_path}")
            else:
                inference_info.status = ProcessingStatus.FAILED
                inference_info.error_message = "æ¨ç†æ‰§è¡Œå¤±è´¥"
                logger.error(f"âŒ æ¨ç†å¤±è´¥: {inference_id}")
                
        except Exception as e:
            inference_info.status = ProcessingStatus.FAILED
            inference_info.error_message = str(e)
            logger.error(f"âŒ æ¨ç†å¼‚å¸¸: {inference_id} - {e}")
    
    # ==================== è¾…åŠ©æ–¹æ³• ====================
    
    def _load_existing_characters(self):
        """åŠ è½½ç°æœ‰è§’è‰²"""
        if not self.characters_dir.exists():
            return
        
        for character_dir in self.characters_dir.iterdir():
            if character_dir.is_dir():
                character_name = character_dir.name
                config_file = character_dir / "character_config.json"
                
                if config_file.exists():
                    try:
                        with open(config_file, 'r', encoding='utf-8') as f:
                            config_data = json.load(f)
                        
                        character_info = CharacterInfo(**config_data)
                        
                        # åŠ¨æ€æ›´æ–°GPUé…ç½®ï¼šå¦‚æœå½“å‰ç¯å¢ƒä¸é…ç½®æ–‡ä»¶ä¸ä¸€è‡´ï¼Œæ›´æ–°é…ç½®
                        current_gpu_env = os.environ.get("CUDA_VISIBLE_DEVICES")
                        if current_gpu_env and character_info.config.gpu_id != current_gpu_env:
                            old_gpu_id = character_info.config.gpu_id
                            character_info.config.gpu_id = current_gpu_env
                            logger.info(f"è§’è‰² {character_name} GPUé…ç½®å·²æ›´æ–°: {old_gpu_id} -> {current_gpu_env}")
                            # ä¿å­˜æ›´æ–°åçš„é…ç½®
                            self._save_character_config(character_name, character_info)
                        
                        characters_db[character_name] = character_info
                        
                        # æ›´æ–°éŸ³é¢‘æ•°é‡å’ŒçŠ¶æ€
                        self.update_character_audio_count(character_name)
                        self._update_character_status(character_name)
                        
                        # è‡ªåŠ¨æ£€æŸ¥æ¨¡å‹çŠ¶æ€
                        if self._check_models_exist(character_name):
                            logger.info(f"âœ… è§’è‰² {character_name} å·²è®­ç»ƒå®Œæˆ")
                            # å°†æ¨¡å‹åŒæ­¥åˆ°è§’è‰²ç›®å½•
                            self._sync_character_models_dir(character_name)
                        else:
                            logger.info(f"âš ï¸  è§’è‰² {character_name} å°šæœªè®­ç»ƒå®Œæˆ")
                        
                        logger.info(f"åŠ è½½è§’è‰²: {character_name}")
                        
                    except Exception as e:
                        logger.warning(f"åŠ è½½è§’è‰²é…ç½®å¤±è´¥ {character_name}: {e}")
    
    def _load_default_character(self):
        """åŠ è½½é»˜è®¤è§’è‰²è®¾ç½®"""
        global default_character
        default_file = self.work_dir / "default_character.txt"
        
        if default_file.exists():
            try:
                with open(default_file, 'r', encoding='utf-8') as f:
                    character_name = f.read().strip()
                
                if character_name in characters_db:
                    default_character = character_name
                    characters_db[character_name].is_default = True
                    logger.info(f"åŠ è½½é»˜è®¤è§’è‰²: {character_name}")
                else:
                    logger.warning(f"é»˜è®¤è§’è‰²ä¸å­˜åœ¨: {character_name}")
                    
            except Exception as e:
                logger.warning(f"åŠ è½½é»˜è®¤è§’è‰²é…ç½®å¤±è´¥: {e}")
    
    def _save_character_config(self, character_name: str, character_info: CharacterInfo):
        """ä¿å­˜è§’è‰²é…ç½®"""
        character_dir = self.get_character_dir(character_name)
        config_file = character_dir / "character_config.json"
        
        config_data = character_info.dict()
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False, default=str)
    
    def _save_default_character(self):
        """ä¿å­˜é»˜è®¤è§’è‰²è®¾ç½®"""
        global default_character
        default_file = self.work_dir / "default_character.txt"
        
        if default_character:
            with open(default_file, 'w', encoding='utf-8') as f:
                f.write(default_character)
    
    def _update_character_status(self, character_name: str):
        """æ›´æ–°è§’è‰²çŠ¶æ€"""
        character_info = characters_db[character_name]
        
        # æ£€æŸ¥éŸ³é¢‘å¤„ç†çŠ¶æ€
        if character_name in audio_processing_db:
            character_info.audio_processing_status = audio_processing_db[character_name].status
        
        # æ£€æŸ¥è®­ç»ƒçŠ¶æ€
        if character_name in training_db:
            character_info.training_status = training_db[character_name].status
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
        character_info.model_exists = self._check_models_exist(character_name)
    
    def _check_models_exist(self, character_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
        # é¦–å…ˆæ£€æŸ¥training_dbä¸­çš„è·¯å¾„
        training_info = training_db.get(character_name)
        if training_info and training_info.gpt_model_path and training_info.sovits_model_path:
            gpt_exists = Path(training_info.gpt_model_path).exists()
            sovits_exists = Path(training_info.sovits_model_path).exists()
            if gpt_exists and sovits_exists:
                return True
        
        # å¦‚æœtraining_dbä¸­æ²¡æœ‰æˆ–è·¯å¾„æ— æ•ˆï¼Œç›´æ¥æŸ¥æ‰¾æ–‡ä»¶ç³»ç»Ÿ
        return self._find_models_in_filesystem(character_name)
    
    def _find_models_in_filesystem(self, character_name: str) -> bool:
        """åœ¨æ–‡ä»¶ç³»ç»Ÿä¸­æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶"""
        try:
            # æŸ¥æ‰¾GPTæ¨¡å‹
            gpt_weights_dir = self.base_dir / "GPT_weights_v2ProPlus"
            if gpt_weights_dir.exists():
                gpt_files = list(gpt_weights_dir.glob(f"{character_name}*.ckpt"))
                if gpt_files:
                    # é€‰æ‹©æœ€æ–°çš„GPTæ¨¡å‹
                    latest_gpt = max(gpt_files, key=lambda x: x.stat().st_mtime)
                    
                    # æŸ¥æ‰¾SoVITSæ¨¡å‹
                    sovits_weights_dir = self.base_dir / "SoVITS_weights_v2ProPlus"
                    if sovits_weights_dir.exists():
                        sovits_files = list(sovits_weights_dir.glob(f"{character_name}*.pth"))
                        if sovits_files:
                            # é€‰æ‹©æœ€æ–°çš„SoVITSæ¨¡å‹
                            latest_sovits = max(sovits_files, key=lambda x: x.stat().st_mtime)
                            
                            # æ›´æ–°training_db
                            if character_name not in training_db:
                                training_db[character_name] = TrainingInfo(
                                    character_name=character_name,
                                    status=ProcessingStatus.COMPLETED,
                                    gpt_model_path=str(latest_gpt),
                                    sovits_model_path=str(latest_sovits)
                                )
                            else:
                                training_db[character_name].gpt_model_path = str(latest_gpt)
                                training_db[character_name].sovits_model_path = str(latest_sovits)
                                training_db[character_name].status = ProcessingStatus.COMPLETED
                            
                            logger.info(f"âœ… å‘ç°å·²è®­ç»ƒçš„æ¨¡å‹: {character_name}")
                            logger.info(f"   GPTæ¨¡å‹: {latest_gpt}")
                            logger.info(f"   SoVITSæ¨¡å‹: {latest_sovits}")
                            # åŒæ­¥æ¨¡å‹åˆ°è§’è‰²ç›®å½•
                            self._sync_character_models_dir(character_name)
                            return True
            
            return False
            
        except Exception as e:
            logger.warning(f"æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶å¤±è´¥ {character_name}: {e}")
            return False
    
    def _sync_character_models_dir(self, character_name: str):
        """å°†å·²å‘ç°/è®­ç»ƒå®Œæˆçš„æ¨¡å‹åŒæ­¥åˆ°è§’è‰²çš„ models ç›®å½•ï¼ˆä½¿ç”¨ç¬¦å·é“¾æ¥ï¼Œè‹¥ä¸æ”¯æŒåˆ™å¤åˆ¶ï¼‰"""
        if character_name not in training_db:
            return
        training_info = training_db[character_name]
        if not training_info.gpt_model_path or not training_info.sovits_model_path:
            return
        gpt_src = Path(training_info.gpt_model_path)
        sovits_src = Path(training_info.sovits_model_path)
        if not gpt_src.exists() or not sovits_src.exists():
            return
        models_dir = self.get_character_models_dir(character_name)
        models_dir.mkdir(parents=True, exist_ok=True)
        gpt_dst = models_dir / gpt_src.name
        sovits_dst = models_dir / sovits_src.name
        
        # å»ºç«‹é“¾æ¥æˆ–å¤åˆ¶
        for src, dst in [(gpt_src, gpt_dst), (sovits_src, sovits_dst)]:
            try:
                if dst.exists():
                    # å·²å­˜åœ¨åˆ™è·³è¿‡
                    continue
                # ä¼˜å…ˆåˆ›å»ºç¬¦å·é“¾æ¥
                dst.symlink_to(src)
            except Exception:
                # å›é€€ä¸ºå¤åˆ¶
                try:
                    shutil.copy2(src, dst)
                except Exception as copy_err:
                    logger.warning(f"åŒæ­¥æ¨¡å‹åˆ°è§’è‰²ç›®å½•å¤±è´¥ {character_name}: {copy_err}")
        
        # åŒæ­¥å®Œæˆåï¼Œæ›´æ–°training_dbä¸­çš„æ¨¡å‹è·¯å¾„ä¸ºè§’è‰²ç›®å½•ä¸‹çš„è·¯å¾„
        if gpt_dst.exists() and sovits_dst.exists():
            training_info.gpt_model_path = str(gpt_dst)
            training_info.sovits_model_path = str(sovits_dst)
            logger.info(f"âœ… æ¨¡å‹è·¯å¾„å·²æ›´æ–°ä¸ºè§’è‰²ç›®å½•: {character_name}")
            logger.info(f"   GPTæ¨¡å‹: {gpt_dst}")
            logger.info(f"   SoVITSæ¨¡å‹: {sovits_dst}")
    
    def _build_training_config(self, character_name: str) -> Dict[str, Any]:
        """æ„å»ºè®­ç»ƒé…ç½®"""
        character_info = characters_db[character_name]
        config = character_info.config
        
        # æŸ¥æ‰¾ASRè¾“å‡ºæ–‡ä»¶
        transcripts_dir = self.get_character_transcripts_dir(character_name)
        asr_output = self._find_asr_output_file(str(transcripts_dir))
        
        if config.enable_denoise:
            wav_dir = str(self.get_character_denoised_audio_dir(character_name))
        else:
            wav_dir = str(self.get_character_sliced_audio_dir(character_name))
        
        # è·å–æ¨¡å‹è·¯å¾„é…ç½®
        model_paths = get_model_paths()
        
        return {
            "ASR_OUTPUT": asr_output,
            "DENOISED_DIR": wav_dir,
            "EXP_NAME": character_name,
            "EXP_DIR": str(self.get_character_experiments_dir(character_name)),
            "BERT_DIR": model_paths["bert_dir"],
            "CNHUBERT_DIR": model_paths["cnhubert_dir"],
            "PRETRAINED_SV": model_paths["pretrained_sv"],
            "BATCH_SIZE": config.batch_size,
            "EPOCHS_S2": config.epochs_s2,
            "EPOCHS_S1": config.epochs_s1,
            "GPU_ID": config.gpu_id,
            "LANGUAGE": config.language,
            "IS_HALF": True,
            "VERSION": "v2ProPlus"
        }
    
    def _find_asr_output_file(self, asr_output_path: str) -> str:
        """æ™ºèƒ½æŸ¥æ‰¾ASRè¾“å‡ºæ–‡ä»¶"""
        asr_path = Path(asr_output_path)
        
        if asr_path.is_file():
            return str(asr_path)
        
        if asr_path.is_dir():
            # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾æ–‡ä»¶
            for pattern in ["*.list", "*.txt", "*.tsv"]:
                files = list(asr_path.glob(pattern))
                if files:
                    return str(files[0])
            
            raise FileNotFoundError(f"åœ¨ASRè¾“å‡ºç›®å½•ä¸­æ‰¾ä¸åˆ°è½¬å½•æ–‡ä»¶: {asr_output_path}")
        
        raise FileNotFoundError(f"ASRè¾“å‡ºè·¯å¾„ä¸å­˜åœ¨: {asr_output_path}")
    
    def _build_step_env(self, config: Dict[str, Any]) -> Dict[str, str]:
        """æ„å»ºæ­¥éª¤æ‰§è¡Œç¯å¢ƒå˜é‡"""
        env = os.environ.copy()
        env.update({
            "inp_text": config["ASR_OUTPUT"],
            "inp_wav_dir": config["DENOISED_DIR"],
            "exp_name": config["EXP_NAME"],
            "opt_dir": config["EXP_DIR"],
            "bert_pretrained_dir": config["BERT_DIR"],
            "cnhubert_base_dir": config["CNHUBERT_DIR"],
            "sv_path": config["PRETRAINED_SV"],
            "s2config_path": "GPT_SoVITS/configs/s2v2ProPlus.json",
            "is_half": "True",
            "BATCH_SIZE": str(config["BATCH_SIZE"]),
            "EPOCHS_S2": str(config["EPOCHS_S2"]),
            "S2_VERSION": "v2ProPlus",
            "_CUDA_VISIBLE_DEVICES": config["GPU_ID"]
        })
        return env
    
    def _find_trained_models(self, character_name: str):
        """æŸ¥æ‰¾è®­ç»ƒç”Ÿæˆçš„æ¨¡å‹æ–‡ä»¶"""
        training_info = training_db[character_name]
        
        try:
            # æŸ¥æ‰¾GPTæ¨¡å‹ - æŒ‰è§’è‰²åç§°æŸ¥æ‰¾
            gpt_weights_dir = self.base_dir / "GPT_weights_v2ProPlus"
            if gpt_weights_dir.exists():
                gpt_files = list(gpt_weights_dir.glob(f"{character_name}*.ckpt"))
                if gpt_files:
                    # é€‰æ‹©æœ€æ–°çš„GPTæ¨¡å‹
                    latest_gpt = max(gpt_files, key=lambda x: x.stat().st_mtime)
                    training_info.gpt_model_path = str(latest_gpt)
                    logger.info(f"âœ… æ‰¾åˆ°GPTæ¨¡å‹: {latest_gpt}")
                else:
                    logger.warning(f"æœªæ‰¾åˆ°è§’è‰² {character_name} çš„GPTæ¨¡å‹")
            
            # æŸ¥æ‰¾SoVITSæ¨¡å‹ - æŒ‰è§’è‰²åç§°æŸ¥æ‰¾
            sovits_weights_dir = self.base_dir / "SoVITS_weights_v2ProPlus"
            if sovits_weights_dir.exists():
                sovits_files = list(sovits_weights_dir.glob(f"{character_name}*.pth"))
                if sovits_files:
                    # é€‰æ‹©æœ€æ–°çš„SoVITSæ¨¡å‹
                    latest_sovits = max(sovits_files, key=lambda x: x.stat().st_mtime)
                    training_info.sovits_model_path = str(latest_sovits)
                    logger.info(f"âœ… æ‰¾åˆ°SoVITSæ¨¡å‹: {latest_sovits}")
                else:
                    logger.warning(f"æœªæ‰¾åˆ°è§’è‰² {character_name} çš„SoVITSæ¨¡å‹")
                    
        except Exception as e:
            logger.warning(f"æŸ¥æ‰¾è®­ç»ƒæ¨¡å‹å¤±è´¥ {character_name}: {e}")
    
    async def _build_inference_params(self, character_name: str, request: InferenceRequest) -> Dict[str, Any]:
        """æ„å»ºæ¨ç†å‚æ•°"""
        training_info = training_db[character_name]
        config = characters_db[character_name].config
        
        # ç¡®å®šå‚è€ƒéŸ³é¢‘
        ref_audio = request.ref_audio
        if not ref_audio:
            # è‡ªåŠ¨é€‰æ‹©å‚è€ƒéŸ³é¢‘
            if config.enable_denoise:
                audio_dir = self.get_character_denoised_audio_dir(character_name)
            else:
                audio_dir = self.get_character_sliced_audio_dir(character_name)
            
            audio_files = list(audio_dir.glob("*.wav"))
            if audio_files:
                ref_audio = str(audio_files[0])
            else:
                raise ValueError(f"æ‰¾ä¸åˆ°å‚è€ƒéŸ³é¢‘æ–‡ä»¶: {character_name}")
        
        # ç¡®å®šå‚è€ƒæ–‡æœ¬
        ref_text = request.ref_text
        if not ref_text:
            # ä»ASRè¾“å‡ºä¸­æå–
            transcripts_dir = self.get_character_transcripts_dir(character_name)
            asr_output = self._find_asr_output_file(str(transcripts_dir))
            
            ref_audio_name = Path(ref_audio).stem
            ref_text = self._extract_ref_text_from_asr(asr_output, ref_audio_name)
        
        # æ„å»ºè¾“å‡ºè·¯å¾„ - åˆ›å»ºå”¯ä¸€çš„è¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir_name = f"{character_name}_{timestamp}"
        output_dir = self.inference_output_dir / output_dir_name
        output_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„ä¸ºç›®å½•ï¼Œinference_cli.pyä¼šåœ¨å…¶ä¸­åˆ›å»ºoutput.wav
        output_path = str(output_dir)
        
        # åˆ›å»ºç›®æ ‡æ–‡æœ¬æ–‡ä»¶
        target_text_file = self.inference_output_dir / f"target_text_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(target_text_file, 'w', encoding='utf-8') as f:
            f.write(request.target_text)
        
        # åˆ›å»ºå‚è€ƒæ–‡æœ¬æ–‡ä»¶
        ref_text_file = self.inference_output_dir / f"ref_text_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(ref_text_file, 'w', encoding='utf-8') as f:
            f.write(ref_text)
        
        # è·å–æ¨¡å‹è·¯å¾„é…ç½®
        model_paths = get_model_paths()
        
        # åŠ¨æ€è·å–GPUè®¾ç½®ï¼šä¼˜å…ˆä½¿ç”¨å½“å‰ç¯å¢ƒçš„CUDA_VISIBLE_DEVICESï¼Œç¡®ä¿ä¸æœåŠ¡å¯åŠ¨ç¯å¢ƒä¸€è‡´
        current_gpu_env = os.environ.get("CUDA_VISIBLE_DEVICES")
        gpu_number = config.gpu_id
        
        logger.info(f"æ¨ç†ä½¿ç”¨GPUè®¾å¤‡: {gpu_number} (ç¯å¢ƒå˜é‡: {current_gpu_env}, è§’è‰²é…ç½®: {config.gpu_id})")
        
        return {
            "gpt_model": training_info.gpt_model_path,
            "sovits_model": training_info.sovits_model_path,
            "ref_audio": ref_audio,
            "ref_text": str(ref_text_file),
            "ref_language": request.ref_language,
            "target_text": str(target_text_file),
            "target_language": request.target_language,
            "output_path": output_path,
            "bert_path": model_paths["bert_dir"],
            "cnhubert_base_path": model_paths["cnhubert_dir"],
            "gpu_number": gpu_number,
            "is_half": True
        }
    
    def _extract_ref_text_from_asr(self, asr_output: str, ref_audio_name: str) -> str:
        """ä»ASRè¾“å‡ºä¸­æå–å‚è€ƒæ–‡æœ¬"""
        try:
            with open(asr_output, 'r', encoding='utf-8') as f:
                for line in f:
                    if ref_audio_name in line:
                        if '|' in line:
                            # .listæ ¼å¼
                            parts = line.strip().split('|')
                            if len(parts) >= 4:
                                return parts[3]
                        elif '\t' in line:
                            # .tsvæ ¼å¼
                            parts = line.strip().split('\t')
                            if len(parts) >= 2:
                                return parts[1]
                        else:
                            # å…¶ä»–æ ¼å¼
                            return line.strip()
                            
            return "è¿™æ˜¯ä¸€ä¸ªå‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬å†…å®¹ã€‚"
            
        except Exception as e:
            logger.warning(f"æå–å‚è€ƒæ–‡æœ¬å¤±è´¥: {e}")
            return "è¿™æ˜¯ä¸€ä¸ªå‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬å†…å®¹ã€‚"

# åˆå§‹åŒ–æœåŠ¡
training_service = CharacterBasedTrainingService()

# ==================== APIè·¯ç”± ====================

# è§’è‰²ç®¡ç†API
@app.post("/api/v1/characters", response_model=CharacterInfo)
async def create_character(request: CharacterCreateRequest):
    """åˆ›å»ºè§’è‰²"""
    try:
        character_info = training_service.create_character(request.character_name, request.config)
        return character_info
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/v1/characters", response_model=List[CharacterInfo])
async def list_characters():
    """åˆ—å‡ºæ‰€æœ‰è§’è‰²"""
    return training_service.list_characters()

@app.get("/api/v1/characters/{character_name}", response_model=CharacterInfo)
async def get_character(character_name: str):
    """è·å–è§’è‰²ä¿¡æ¯"""
    try:
        return training_service.get_character(character_name)
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))

@app.put("/api/v1/characters/{character_name}", response_model=CharacterInfo)
async def rename_character(character_name: str, request: CharacterRenameRequest):
    """é‡å‘½åè§’è‰²"""
    try:
        return training_service.rename_character(character_name, request.new_name)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.delete("/api/v1/characters/{character_name}")
async def delete_character(character_name: str):
    """åˆ é™¤è§’è‰²"""
    try:
        success = training_service.delete_character(character_name)
        return {"message": "è§’è‰²åˆ é™¤æˆåŠŸ", "success": success}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))

@app.post("/api/v1/characters/{character_name}/set_default")
async def set_default_character(character_name: str):
    """è®¾ç½®é»˜è®¤è§’è‰²"""
    try:
        success = training_service.set_default_character(character_name)
        return {"message": "é»˜è®¤è§’è‰²è®¾ç½®æˆåŠŸ", "success": success}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))

@app.get("/api/v1/default_character")
async def get_default_character():
    """è·å–é»˜è®¤è§’è‰²"""
    default_char = training_service.get_default_character()
    return {"default_character": default_char}

# éŸ³é¢‘ä¸Šä¼ API
@app.post("/api/v1/characters/{character_name}/audio/upload")
async def upload_audio(character_name: str, file: UploadFile = File(...)):
    """ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"""
    try:
        character_info = training_service.get_character(character_name)
    except ValueError:
        raise HTTPException(status_code=404, detail="è§’è‰²ä¸å­˜åœ¨")
    
    # è·å–è§’è‰²éŸ³é¢‘ç›®å½•
    audio_dir = training_service.get_character_raw_audio_dir(character_name)
    file_path = audio_dir / file.filename
    
    # ä¿å­˜æ–‡ä»¶
    with open(file_path, "wb") as f:
        content = await file.read()
        f.write(content)
    
    # æ›´æ–°éŸ³é¢‘æ•°é‡
    training_service.update_character_audio_count(character_name)
    
    return {"message": "éŸ³é¢‘ä¸Šä¼ æˆåŠŸ", "filename": file.filename, "path": str(file_path)}

# éŸ³é¢‘å¤„ç†API
@app.post("/api/v1/characters/{character_name}/audio/process", response_model=AudioProcessingInfo)
async def start_audio_processing(character_name: str, background_tasks: BackgroundTasks):
    """å¼€å§‹éŸ³é¢‘å¤„ç†"""
    try:
        processing_info = await training_service.start_audio_processing(character_name)
        return processing_info
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/v1/characters/{character_name}/audio/status", response_model=AudioProcessingInfo)
async def get_audio_processing_status(character_name: str):
    """è·å–éŸ³é¢‘å¤„ç†çŠ¶æ€"""
    if character_name not in audio_processing_db:
        raise HTTPException(status_code=404, detail="éŸ³é¢‘å¤„ç†è®°å½•ä¸å­˜åœ¨")
    return audio_processing_db[character_name]

# è®­ç»ƒAPI
@app.post("/api/v1/characters/{character_name}/training/start", response_model=TrainingInfo)
async def start_training(character_name: str, background_tasks: BackgroundTasks):
    """å¼€å§‹è®­ç»ƒ"""
    try:
        training_info = await training_service.start_training(character_name)
        return training_info
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/v1/characters/{character_name}/training/status", response_model=TrainingInfo)
async def get_training_status(character_name: str):
    """è·å–è®­ç»ƒçŠ¶æ€"""
    if character_name not in training_db:
        raise HTTPException(status_code=404, detail="è®­ç»ƒè®°å½•ä¸å­˜åœ¨")
    return training_db[character_name]

# æ¨ç†API
@app.post("/api/v1/inference", response_model=InferenceInfo)
async def start_inference(request: InferenceRequest, background_tasks: BackgroundTasks):
    """å¼€å§‹æ¨ç†"""
    try:
        inference_info = await training_service.start_inference(request)
        return inference_info
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/v1/inference/{inference_id}", response_model=InferenceInfo)
async def get_inference_status(inference_id: str):
    """è·å–æ¨ç†çŠ¶æ€"""
    if inference_id not in inference_db:
        raise HTTPException(status_code=404, detail="æ¨ç†è®°å½•ä¸å­˜åœ¨")
    return inference_db[inference_id]

@app.get("/api/v1/inference")
async def list_inference():
    """åˆ—å‡ºæ‰€æœ‰æ¨ç†è®°å½•"""
    return list(inference_db.values())

# æ–‡ä»¶ä¸‹è½½API
@app.get("/api/v1/characters/{character_name}/download/{filename}")
async def download_character_file(character_name: str, filename: str):
    """ä¸‹è½½è§’è‰²ç›¸å…³æ–‡ä»¶"""
    try:
        character_info = training_service.get_character(character_name)
    except ValueError:
        raise HTTPException(status_code=404, detail="è§’è‰²ä¸å­˜åœ¨")
    
    # æŸ¥æ‰¾æ–‡ä»¶
    character_dir = training_service.get_character_dir(character_name)
    search_dirs = [
        character_dir / "models",
        character_dir / "experiments" / character_name,
        character_dir,
        training_service.inference_output_dir
    ]
    
    file_path = None
    for search_dir in search_dirs:
        candidate_path = search_dir / filename
        if candidate_path.exists():
            file_path = candidate_path
            break
    
    if not file_path:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    return FileResponse(file_path, filename=filename)

@app.get("/api/v1/inference/{inference_id}/download")
async def download_inference_result(inference_id: str):
    """ä¸‹è½½æ¨ç†ç»“æœ"""
    if inference_id not in inference_db:
        raise HTTPException(status_code=404, detail="æ¨ç†è®°å½•ä¸å­˜åœ¨")
    
    inference_info = inference_db[inference_id]
    
    if inference_info.status != ProcessingStatus.COMPLETED:
        raise HTTPException(status_code=400, detail="æ¨ç†å°šæœªå®Œæˆ")
    
    if not inference_info.output_path or not Path(inference_info.output_path).exists():
        raise HTTPException(status_code=404, detail="æ¨ç†ç»“æœæ–‡ä»¶ä¸å­˜åœ¨")
    
    filename = f"{inference_info.character_name}_{inference_id[:8]}.wav"
    return FileResponse(inference_info.output_path, filename=filename)

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "GPT-SoVITS åŸºäºè§’è‰²çš„è®­ç»ƒæœåŠ¡API",
        "version": "2.0.0",
        "docs_url": "/docs",
        "features": [
            "è§’è‰²ç®¡ç†",
            "éŸ³é¢‘å¤„ç†",
            "æ¨¡å‹è®­ç»ƒ", 
            "è¯­éŸ³æ¨ç†"
        ]
    }

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="GPT-SoVITSè®­ç»ƒæœåŠ¡API",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python training_service.py                    # ä½¿ç”¨é»˜è®¤ç«¯å£8000
  python training_service.py --port 8216       # æŒ‡å®šç«¯å£8216
  python training_service.py -p 9000           # ä½¿ç”¨çŸ­å‚æ•°æŒ‡å®šç«¯å£
  python training_service.py --host 127.0.0.1  # æŒ‡å®šä¸»æœºåœ°å€
  python training_service.py --config          # æ˜¾ç¤ºå½“å‰é…ç½®
  python training_service.py --help            # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        """
    )
    
    parser.add_argument(
        "-p", "--port",
        type=int,
        default=None,
        help="æœåŠ¡ç«¯å£å· (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)"
    )
    
    parser.add_argument(
        "-H", "--host",
        type=str,
        default=None,
        help="ç»‘å®šä¸»æœºåœ°å€ (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)"
    )
    
    parser.add_argument(
        "--workers",
        type=int,
        default=None,
        help="å·¥ä½œè¿›ç¨‹æ•° (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)"
    )
    
    parser.add_argument(
        "--log-level",
        type=str,
        default=None,
        choices=["debug", "info", "warning", "error"],
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)"
    )
    
    parser.add_argument(
        "--reload",
        action="store_true",
        help="å¼€å‘æ¨¡å¼ï¼šä»£ç å˜æ›´æ—¶è‡ªåŠ¨é‡è½½"
    )
    
    parser.add_argument(
        "--config",
        action="store_true",
        help="æ˜¾ç¤ºå½“å‰é…ç½®ä¿¡æ¯"
    )
    
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_arguments()
    
    # å¦‚æœåªæ˜¯æ˜¾ç¤ºé…ç½®ï¼Œåˆ™æ˜¾ç¤ºåé€€å‡º
    if args.config:
        if os.getenv('GPT_SOVITS_SERVER_MODE') == 'standalone':
            from service_config import print_config
        else:
            from .service_config import print_config
        print_config()
        exit(0)
    
    # å¯¼å…¥é…ç½®
    if os.getenv('GPT_SOVITS_SERVER_MODE') == 'standalone':
        from service_config import SERVICE_CONFIG
    else:
        from .service_config import SERVICE_CONFIG
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶çš„å€¼
    host = args.host or SERVICE_CONFIG["host"]
    port = args.port or SERVICE_CONFIG["port"]
    workers = args.workers or SERVICE_CONFIG["workers"]
    log_level = args.log_level or SERVICE_CONFIG["log_level"]
    
    logger.info(f"ğŸš€ å¯åŠ¨ GPT-SoVITS è®­ç»ƒæœåŠ¡API")
    logger.info(f"ğŸ“ æœåŠ¡åœ°å€: http://{host}:{port}")
    logger.info(f"ğŸ“š APIæ–‡æ¡£: http://{host}:{port}/docs")
    logger.info(f"ğŸ”§ å·¥ä½œè¿›ç¨‹: {workers}")
    logger.info(f"ğŸ“ æ—¥å¿—çº§åˆ«: {log_level}")
    logger.info(f"ğŸ”„ è‡ªåŠ¨é‡è½½: {'å¼€å¯' if args.reload else 'å…³é—­'}")
    logger.info("=" * 50)
    
    if args.reload:
        # ä½¿ç”¨ reload æ¨¡å¼æ—¶ï¼Œå¿…é¡»ä½¿ç”¨æ¨¡å—å¯¼å…¥å­—ç¬¦ä¸²
        uvicorn.run(
            "server.training_service:app",
            host=host, 
            port=port,
            workers=1,  # reload æ¨¡å¼ä¸‹ workers å¿…é¡»ä¸º 1
            log_level=log_level,
            reload=True
        )
    else:
        # é reload æ¨¡å¼æ—¶ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åº”ç”¨å¯¹è±¡
        uvicorn.run(
            app, 
            host=host, 
            port=port,
            workers=workers,
            log_level=log_level,
            reload=False
        )
