#!/usr/bin/env python3
"""
GPT-SoVITSè®­ç»ƒæœåŠ¡API
æä¾›å®Œæ•´çš„è¯­éŸ³å…‹éš†è®­ç»ƒæµç¨‹APIæ¥å£
"""

import os
import sys
import json
import uuid
import asyncio
import subprocess
import argparse
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path
from enum import Enum

from fastapi import FastAPI, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import FileResponse
from pydantic import BaseModel, Field
import uvicorn

# å¯¼å…¥æ­¥éª¤å¤„ç†å™¨å’Œé…ç½®
import os

# æ ¹æ®è¿è¡Œç¯å¢ƒé€‰æ‹©å¯¼å…¥æ–¹å¼
if os.getenv('GPT_SOVITS_SERVER_MODE') == 'standalone':
    # ç‹¬ç«‹è¿è¡Œæ¨¡å¼ï¼ˆä»serverç›®å½•ç›´æ¥è¿è¡Œï¼‰
    from training_steps import StepProcessor, ConfigGenerator
    from service_config import get_base_path, get_work_dir, get_model_paths
else:
    # åŒ…æ¨¡å¼ï¼ˆä»æ ¹ç›®å½•å¯¼å…¥ï¼‰
    from .training_steps import StepProcessor, ConfigGenerator
    from .service_config import get_base_path, get_work_dir, get_model_paths

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('training_service.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

# ä»»åŠ¡çŠ¶æ€æšä¸¾
class TaskStatus(str, Enum):
    CREATED = "created"
    RUNNING = "running" 
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

# è®­ç»ƒæ­¥éª¤æšä¸¾
class TrainingStep(str, Enum):
    CONVERT_AUDIO = "convert_audio"
    SLICE_AUDIO = "slice_audio"
    DENOISE_AUDIO = "denoise_audio"
    ASR_TRANSCRIBE = "asr_transcribe"
    EXTRACT_TEXT_FEATURES = "extract_text_features"
    EXTRACT_AUDIO_FEATURES = "extract_audio_features"
    EXTRACT_SPEAKER_VECTORS = "extract_speaker_vectors"
    EXTRACT_SEMANTIC_FEATURES = "extract_semantic_features"
    TRAIN_SOVITS = "train_sovits"
    TRAIN_GPT = "train_gpt"
    TEST_INFERENCE = "test_inference"

# æ•°æ®æ¨¡å‹
class TaskConfig(BaseModel):
    exp_name: str = Field(default="my_speaker", description="å®éªŒåç§°")
    language: str = Field(default="zh", description="è¯­è¨€è®¾ç½®")
    batch_size: int = Field(default=16, description="æ‰¹æ¬¡å¤§å°")
    epochs_s2: int = Field(default=50, description="SoVITSè®­ç»ƒè½®æ•°")
    epochs_s1: int = Field(default=15, description="GPTè®­ç»ƒè½®æ•°")
    gpu_id: str = Field(default=os.environ.get("CUDA_VISIBLE_DEVICES", "0"), description="GPUè®¾å¤‡ID")

class TaskCreateRequest(BaseModel):
    task_name: str = Field(description="ä»»åŠ¡åç§°")
    config: TaskConfig = Field(description="è®­ç»ƒé…ç½®")

class TaskInfo(BaseModel):
    task_id: str
    task_name: str
    status: TaskStatus
    config: TaskConfig
    created_at: datetime
    updated_at: datetime
    current_step: Optional[str] = None
    progress: float = 0.0
    error_message: Optional[str] = None

class StepExecuteRequest(BaseModel):
    params: Optional[Dict[str, Any]] = Field(default_factory=dict, description="æ­¥éª¤ç‰¹å®šå‚æ•°")

# å…¨å±€ä»»åŠ¡å­˜å‚¨
tasks_db: Dict[str, TaskInfo] = {}
step_processes: Dict[str, subprocess.Popen] = {}

# FastAPIåº”ç”¨
app = FastAPI(
    title="GPT-SoVITSè®­ç»ƒæœåŠ¡",
    description="æä¾›å®Œæ•´çš„è¯­éŸ³å…‹éš†è®­ç»ƒæµç¨‹APIæ¥å£",
    version="1.0.0"
)

class TrainingService:
    """è®­ç»ƒæœåŠ¡æ ¸å¿ƒç±»"""
    
    def __init__(self):
        # ä½¿ç”¨é…ç½®æ–‡ä»¶è·å–è·¯å¾„
        self.base_dir = get_base_path()
        self.work_dir = get_work_dir()
        
        self.step_processor = StepProcessor(str(self.base_dir))
        self.config_generator = ConfigGenerator(str(self.base_dir))
        
        logger.info(f"âœ… åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"   åŸºç¡€ç›®å½•: {self.base_dir}")
        logger.info(f"   å·¥ä½œç›®å½•: {self.work_dir}")
    
    def get_task_dir(self, task_id: str) -> Path:
        """è·å–ä»»åŠ¡å·¥ä½œç›®å½•"""
        task_dir = self.work_dir / task_id
        task_dir.mkdir(exist_ok=True)
        return task_dir
    
    def get_task_input_dir(self, task_id: str) -> Path:
        """è·å–ä»»åŠ¡è¾“å…¥ç›®å½•"""
        input_dir = self.get_task_dir(task_id) / "input_audio"
        input_dir.mkdir(exist_ok=True)
        return input_dir
    
    def get_task_output_dir(self, task_id: str) -> Path:
        """è·å–ä»»åŠ¡è¾“å‡ºç›®å½•"""
        output_dir = self.get_task_dir(task_id) / "output"
        output_dir.mkdir(exist_ok=True)
        return output_dir
    
    def create_task_config_file(self, task_id: str, config: TaskConfig) -> Path:
        """åˆ›å»ºä»»åŠ¡é…ç½®æ–‡ä»¶"""
        task_dir = self.get_task_dir(task_id)
        config_file = task_dir / "task_config.json"
        
        # è·å–æ¨¡å‹è·¯å¾„é…ç½®
        model_paths = get_model_paths()
        
        # åŸºäºåŸå§‹è„šæœ¬çš„é…ç½®ç»“æ„
        task_config = {
            "INPUT_AUDIO": str(self.get_task_input_dir(task_id)),
            "WORK_DIR": str(task_dir),
            "EXP_NAME": config.exp_name,
            "EXP_DIR": str(task_dir / "experiments" / config.exp_name),
            "SLICED_DIR": str(task_dir / "sliced"),
            "DENOISED_DIR": str(task_dir / "denoised"), 
            "ASR_OUTPUT": str(task_dir / "transcripts"),
            "BERT_DIR": model_paths["bert_dir"],
            "CNHUBERT_DIR": model_paths["cnhubert_dir"],
            "PRETRAINED_SV": model_paths["pretrained_sv"],
            "BATCH_SIZE": config.batch_size,
            "EPOCHS_S2": config.epochs_s2,
            "EPOCHS_S1": config.epochs_s1,
            "GPU_ID": config.gpu_id,
            "LANGUAGE": config.language
        }
        
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(task_config, f, indent=2, ensure_ascii=False)
        
        return config_file
    
    def load_task_config(self, task_id: str) -> Dict[str, Any]:
        """åŠ è½½ä»»åŠ¡é…ç½®"""
        config_file = self.get_task_dir(task_id) / "task_config.json"
        if not config_file.exists():
            raise FileNotFoundError(f"ä»»åŠ¡é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    async def execute_step(self, task_id: str, step: TrainingStep, params: Dict[str, Any] = None):
        """æ‰§è¡Œè®­ç»ƒæ­¥éª¤"""
        if task_id not in tasks_db:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        task_info = tasks_db[task_id]
        if task_info.status == TaskStatus.RUNNING:
            raise HTTPException(status_code=400, detail="ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        task_info.status = TaskStatus.RUNNING
        task_info.current_step = step
        task_info.updated_at = datetime.now()
        
        # è®¾ç½®å½“å‰æ­¥éª¤çš„èµ·å§‹è¿›åº¦
        step_start_progress = self.get_step_progress(task_id, step)
        task_info.progress = step_start_progress
        logger.info(f"æ­¥éª¤ {step.value} å¼€å§‹æ‰§è¡Œï¼Œèµ·å§‹è¿›åº¦: {step_start_progress:.1f}%")
        
        try:
            config = self.load_task_config(task_id)
            success = False
            
            # ä½¿ç”¨StepProcessoræ‰§è¡Œå…·ä½“æ­¥éª¤
            if step == TrainingStep.CONVERT_AUDIO:
                success = await self.step_processor.convert_audio(
                    config["INPUT_AUDIO"],
                    config["WORK_DIR"] + "/converted_wav"
                )
                # æ›´æ–°é…ç½®ä¸­çš„è¾“å…¥ç›®å½•
                if success:
                    config["INPUT_AUDIO"] = config["WORK_DIR"] + "/converted_wav"
                    self._save_task_config(task_id, config)
                    
            elif step == TrainingStep.SLICE_AUDIO:
                success = await self.step_processor.slice_audio(
                    config["INPUT_AUDIO"],
                    config["SLICED_DIR"],
                    **(params or {})
                )
                
            elif step == TrainingStep.DENOISE_AUDIO:
                success = await self.step_processor.denoise_audio(
                    config["SLICED_DIR"],
                    config["DENOISED_DIR"],
                    params.get("precision", "float16") if params else "float16"
                )
                
            elif step == TrainingStep.ASR_TRANSCRIBE:
                success = await self.step_processor.asr_transcribe(
                    config["DENOISED_DIR"],
                    config["ASR_OUTPUT"],
                    config["LANGUAGE"],
                    params.get("precision", "float16") if params else "float16"
                )
                
            elif step == TrainingStep.EXTRACT_TEXT_FEATURES:
                # ä¿®å¤ï¼šç¡®ä¿ASRè¾“å‡ºæŒ‡å‘å…·ä½“çš„æ–‡ä»¶è€Œä¸æ˜¯ç›®å½•
                try:
                    asr_output = self._find_asr_output_file(config["ASR_OUTPUT"])
                    if asr_output != config["ASR_OUTPUT"]:
                        logger.info(f"âœ… æ‰¾åˆ°ASRè¾“å‡ºæ–‡ä»¶: {asr_output}")
                        # æ›´æ–°é…ç½®
                        config["ASR_OUTPUT"] = asr_output
                        self._save_task_config(task_id, config)
                except FileNotFoundError as e:
                    logger.error(f"âŒ ASRè¾“å‡ºæ–‡ä»¶æŸ¥æ‰¾å¤±è´¥: {e}")
                    task_info.status = TaskStatus.FAILED
                    task_info.error_message = str(e)
                    return
                
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "1-get-text.py", env_vars, parallel_parts, gpu_ids
                )
                
                if success:
                    # åˆå¹¶åˆ†ç‰‡æ–‡ä»¶
                    await self.step_processor.merge_feature_files(
                        config["EXP_DIR"], "2-name2text-{}.txt", "2-name2text.txt", 
                        has_header=False, parallel_parts=parallel_parts
                    )
                    
            elif step == TrainingStep.EXTRACT_AUDIO_FEATURES:
                # ä¿®å¤ï¼šç¡®ä¿ASRè¾“å‡ºæŒ‡å‘å…·ä½“çš„æ–‡ä»¶è€Œä¸æ˜¯ç›®å½•
                try:
                    asr_output = self._find_asr_output_file(config["ASR_OUTPUT"])
                    if asr_output != config["ASR_OUTPUT"]:
                        logger.info(f"âœ… æ‰¾åˆ°ASRè¾“å‡ºæ–‡ä»¶: {asr_output}")
                        # æ›´æ–°é…ç½®
                        config["ASR_OUTPUT"] = asr_output
                        self._save_task_config(task_id, config)
                except FileNotFoundError as e:
                    logger.error(f"âŒ ASRè¾“å‡ºæ–‡ä»¶æŸ¥æ‰¾å¤±è´¥: {e}")
                    task_info.status = TaskStatus.FAILED
                    task_info.error_message = str(e)
                    return
                
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "2-get-hubert-wav32k.py", env_vars, parallel_parts, gpu_ids
                )
                
            elif step == TrainingStep.EXTRACT_SPEAKER_VECTORS:
                # ä¿®å¤ï¼šç¡®ä¿ASRè¾“å‡ºæŒ‡å‘å…·ä½“çš„æ–‡ä»¶è€Œä¸æ˜¯ç›®å½•
                try:
                    asr_output = self._find_asr_output_file(config["ASR_OUTPUT"])
                    if asr_output != config["ASR_OUTPUT"]:
                        logger.info(f"âœ… æ‰¾åˆ°ASRè¾“å‡ºæ–‡ä»¶: {asr_output}")
                        # æ›´æ–°é…ç½®
                        config["ASR_OUTPUT"] = asr_output
                        self._save_task_config(task_id, config)
                except FileNotFoundError as e:
                    logger.error(f"âŒ ASRè¾“å‡ºæ–‡ä»¶æŸ¥æ‰¾å¤±è´¥: {e}")
                    task_info.status = TaskStatus.FAILED
                    task_info.error_message = str(e)
                    return
                
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "2-get-sv.py", env_vars, parallel_parts, gpu_ids
                )
                
            elif step == TrainingStep.EXTRACT_SEMANTIC_FEATURES:
                # ä¿®å¤ï¼šç¡®ä¿ASRè¾“å‡ºæŒ‡å‘å…·ä½“çš„æ–‡ä»¶è€Œä¸æ˜¯ç›®å½•
                try:
                    asr_output = self._find_asr_output_file(config["ASR_OUTPUT"])
                    if asr_output != config["ASR_OUTPUT"]:
                        logger.info(f"âœ… æ‰¾åˆ°ASRè¾“å‡ºæ–‡ä»¶: {asr_output}")
                        # æ›´æ–°é…ç½®
                        config["ASR_OUTPUT"] = asr_output
                        self._save_task_config(task_id, config)
                except FileNotFoundError as e:
                    logger.error(f"âŒ ASRè¾“å‡ºæ–‡ä»¶æŸ¥æ‰¾å¤±è´¥: {e}")
                    task_info.status = TaskStatus.FAILED
                    task_info.error_message = str(e)
                    return
                
                env_vars = self._build_step_env(config)
                gpu_ids = config["GPU_ID"]
                parallel_parts = len(gpu_ids.split('-')) if '-' in gpu_ids else 1
                
                success = await self.step_processor.extract_features(
                    "3-get-semantic.py", env_vars, parallel_parts, gpu_ids
                )
                
                if success:
                    # åˆå¹¶åˆ†ç‰‡æ–‡ä»¶
                    await self.step_processor.merge_feature_files(
                        config["EXP_DIR"], "6-name2semantic-{}.tsv", "6-name2semantic.tsv", 
                        has_header=True, parallel_parts=parallel_parts
                    )
                    
            elif step == TrainingStep.TRAIN_SOVITS:
                # ç”ŸæˆS2é…ç½®æ–‡ä»¶
                s2_config_path = config["WORK_DIR"] + "/config_s2.json"
                self.config_generator.generate_s2_config(config, s2_config_path)
                
                success = await self.step_processor.train_model(
                    "s2_train.py", s2_config_path
                )
                
            elif step == TrainingStep.TRAIN_GPT:
                # ç”ŸæˆS1é…ç½®æ–‡ä»¶
                s1_config_path = config["WORK_DIR"] + "/config_s1.yaml"
                self.config_generator.generate_s1_config(config, s1_config_path)
                
                env_vars = {"hz": "25hz"}
                success = await self.step_processor.train_model(
                    "s1_train.py", s1_config_path, env_vars
                )
                
            elif step == TrainingStep.TEST_INFERENCE:
                inference_params = params or {}
                inference_params.update({
                    "output_path": config["WORK_DIR"] + "/output",
                    "bert_path": config["BERT_DIR"],
                    "cnhubert_base_path": config["CNHUBERT_DIR"],
                    "gpu_number": config["GPU_ID"],
                    "is_half": True
                })
                
                success = await self.step_processor.test_inference(**inference_params)
                
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è®­ç»ƒæ­¥éª¤: {step}")
            
            if success:
                task_info.status = TaskStatus.COMPLETED
                self._update_progress(task_id, step)
                logger.info(f"æ­¥éª¤ {step.value} æ‰§è¡ŒæˆåŠŸï¼Œä»»åŠ¡ {task_id} è¿›åº¦æ›´æ–°å®Œæˆ")
            else:
                task_info.status = TaskStatus.FAILED
                task_info.error_message = f"æ­¥éª¤ {step} æ‰§è¡Œå¤±è´¥"
                logger.error(f"æ­¥éª¤ {step.value} æ‰§è¡Œå¤±è´¥ï¼Œä»»åŠ¡ {task_id} çŠ¶æ€æ›´æ–°ä¸ºå¤±è´¥")
                
        except Exception as e:
            task_info.status = TaskStatus.FAILED
            task_info.error_message = str(e)
        finally:
            task_info.updated_at = datetime.now()
    
    def _save_task_config(self, task_id: str, config: Dict[str, Any]):
        """ä¿å­˜ä»»åŠ¡é…ç½®"""
        config_file = self.get_task_dir(task_id) / "task_config.json"
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def _find_asr_output_file(self, asr_output_path: str) -> str:
        """æ™ºèƒ½æŸ¥æ‰¾ASRè¾“å‡ºæ–‡ä»¶"""
        asr_path = Path(asr_output_path)
        
        if asr_path.is_file():
            # å¦‚æœå·²ç»æ˜¯æ–‡ä»¶ï¼Œç›´æ¥è¿”å›
            return str(asr_path)
        
        if asr_path.is_dir():
            # å¦‚æœæ˜¯ç›®å½•ï¼ŒæŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾æ–‡ä»¶
            # ä¼˜å…ˆçº§1: .listæ–‡ä»¶ï¼ˆæ ‡å‡†æ ¼å¼ï¼‰
            list_files = list(asr_path.glob("*.list"))
            if list_files:
                return str(list_files[0])
            
            # ä¼˜å…ˆçº§2: .txtæ–‡ä»¶
            txt_files = list(asr_path.glob("*.txt"))
            if txt_files:
                return str(txt_files[0])
            
            # ä¼˜å…ˆçº§3: .tsvæ–‡ä»¶
            tsv_files = list(asr_path.glob("*.tsv"))
            if tsv_files:
                return str(tsv_files[0])
            
            # ä¼˜å…ˆçº§4: ä»»ä½•å…¶ä»–æ–‡ä»¶
            other_files = list(asr_path.glob("*"))
            if other_files:
                return str(other_files[0])
            
            # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼ŒæŠ›å‡ºé”™è¯¯
            raise FileNotFoundError(f"åœ¨ASRè¾“å‡ºç›®å½•ä¸­æ‰¾ä¸åˆ°è½¬å½•æ–‡ä»¶: {asr_output_path}")
        
        # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼ŒæŠ›å‡ºé”™è¯¯
        raise FileNotFoundError(f"ASRè¾“å‡ºè·¯å¾„ä¸å­˜åœ¨: {asr_output_path}")
    

    def _build_step_env(self, config: Dict[str, Any]) -> Dict[str, str]:
        """æ„å»ºæ­¥éª¤æ‰§è¡Œç¯å¢ƒå˜é‡"""
        env = os.environ.copy()
        env.update({
            "inp_text": config["ASR_OUTPUT"],
            "inp_wav_dir": config["DENOISED_DIR"],
            "exp_name": config["EXP_NAME"],
            "opt_dir": config["EXP_DIR"],
            "bert_pretrained_dir": config["BERT_DIR"],
            "cnhubert_base_dir": config["CNHUBERT_DIR"],
            "sv_path": config["PRETRAINED_SV"],
            "s2config_path": "GPT_SoVITS/configs/s2v2ProPlus.json",
            "is_half": "True",
            "BATCH_SIZE": str(config["BATCH_SIZE"]),
            "EPOCHS_S2": str(config["EPOCHS_S2"]),
            "S2_VERSION": "v2ProPlus",
            "_CUDA_VISIBLE_DEVICES": config["GPU_ID"]
        })
        return env
    
    def _update_progress(self, task_id: str, completed_step: TrainingStep):
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        if task_id not in tasks_db:
            return
        
        # å®šä¹‰æ­¥éª¤é¡ºåºå’Œæƒé‡ï¼ˆæŒ‰å®é™…æ‰§è¡Œé¡ºåºï¼‰
        step_sequence = [
            TrainingStep.CONVERT_AUDIO,
            TrainingStep.SLICE_AUDIO,
            TrainingStep.DENOISE_AUDIO,
            TrainingStep.ASR_TRANSCRIBE,
            TrainingStep.EXTRACT_TEXT_FEATURES,
            TrainingStep.EXTRACT_AUDIO_FEATURES,
            TrainingStep.EXTRACT_SPEAKER_VECTORS,
            TrainingStep.EXTRACT_SEMANTIC_FEATURES,
            TrainingStep.TRAIN_SOVITS,
            TrainingStep.TRAIN_GPT,
            TrainingStep.TEST_INFERENCE
        ]
        
        # å®šä¹‰æ­¥éª¤æƒé‡ï¼ˆåŸºäºå®é™…å¤æ‚åº¦å’Œæ—¶é—´ï¼‰
        step_weights = {
            TrainingStep.CONVERT_AUDIO: 3,        # éŸ³é¢‘è½¬æ¢ï¼Œç›¸å¯¹ç®€å•
            TrainingStep.SLICE_AUDIO: 5,          # éŸ³é¢‘åˆ‡ç‰‡ï¼Œä¸­ç­‰å¤æ‚åº¦
            TrainingStep.DENOISE_AUDIO: 8,        # éŸ³é¢‘é™å™ªï¼Œè¾ƒå¤æ‚
            TrainingStep.ASR_TRANSCRIBE: 10,      # è¯­éŸ³è¯†åˆ«ï¼Œå¤æ‚
            TrainingStep.EXTRACT_TEXT_FEATURES: 8, # æ–‡æœ¬ç‰¹å¾æå–ï¼Œä¸­ç­‰å¤æ‚åº¦
            TrainingStep.EXTRACT_AUDIO_FEATURES: 12, # éŸ³é¢‘ç‰¹å¾æå–ï¼Œå¤æ‚
            TrainingStep.EXTRACT_SPEAKER_VECTORS: 8, # è¯´è¯äººå‘é‡æå–ï¼Œä¸­ç­‰å¤æ‚åº¦
            TrainingStep.EXTRACT_SEMANTIC_FEATURES: 10, # è¯­ä¹‰ç‰¹å¾æå–ï¼Œå¤æ‚
            TrainingStep.TRAIN_SOVITS: 20,        # SoVITSè®­ç»ƒï¼Œæœ€å¤æ‚
            TrainingStep.TRAIN_GPT: 20,           # GPTè®­ç»ƒï¼Œæœ€å¤æ‚
            TrainingStep.TEST_INFERENCE: 6        # æ¨ç†æµ‹è¯•ï¼Œä¸­ç­‰å¤æ‚åº¦
        }
        
        # è®¡ç®—å·²å®Œæˆæ­¥éª¤çš„æƒé‡
        total_weight = sum(step_weights.values())
        completed_weight = 0
        
        for step in step_sequence:
            if step == completed_step:
                # å½“å‰æ­¥éª¤å®Œæˆï¼ŒåŠ ä¸Šå…¶æƒé‡
                completed_weight += step_weights[step]
                break
            else:
                # ä¹‹å‰æ­¥éª¤å·²å®Œæˆï¼ŒåŠ ä¸Šå…¶æƒé‡
                completed_weight += step_weights[step]
        
        # æ›´æ–°è¿›åº¦
        progress = min(100.0, (completed_weight / total_weight) * 100)
        tasks_db[task_id].progress = progress
        
        logger.info(f"ä»»åŠ¡ {task_id} è¿›åº¦æ›´æ–°: {completed_step.value} å®Œæˆï¼Œæ€»è¿›åº¦: {progress:.1f}%")
    
    def get_step_progress(self, task_id: str, current_step: TrainingStep) -> float:
        """è·å–å½“å‰æ­¥éª¤çš„è¿›åº¦ç™¾åˆ†æ¯”"""
        # å®šä¹‰æ­¥éª¤é¡ºåºå’Œæƒé‡ï¼ˆä¸_update_progressä¿æŒä¸€è‡´ï¼‰
        step_sequence = [
            TrainingStep.CONVERT_AUDIO,
            TrainingStep.SLICE_AUDIO,
            TrainingStep.DENOISE_AUDIO,
            TrainingStep.ASR_TRANSCRIBE,
            TrainingStep.EXTRACT_TEXT_FEATURES,
            TrainingStep.EXTRACT_AUDIO_FEATURES,
            TrainingStep.EXTRACT_SPEAKER_VECTORS,
            TrainingStep.EXTRACT_SEMANTIC_FEATURES,
            TrainingStep.TRAIN_SOVITS,
            TrainingStep.TRAIN_GPT,
            TrainingStep.TEST_INFERENCE
        ]
        
        step_weights = {
            TrainingStep.CONVERT_AUDIO: 3,
            TrainingStep.SLICE_AUDIO: 5,
            TrainingStep.DENOISE_AUDIO: 8,
            TrainingStep.ASR_TRANSCRIBE: 10,
            TrainingStep.EXTRACT_TEXT_FEATURES: 8,
            TrainingStep.EXTRACT_AUDIO_FEATURES: 12,
            TrainingStep.EXTRACT_SPEAKER_VECTORS: 8,
            TrainingStep.EXTRACT_SEMANTIC_FEATURES: 10,
            TrainingStep.TRAIN_SOVITS: 20,
            TrainingStep.TRAIN_GPT: 20,
            TrainingStep.TEST_INFERENCE: 6
        }
        
        # è®¡ç®—å½“å‰æ­¥éª¤ä¹‹å‰çš„ç´¯è®¡æƒé‡
        total_weight = sum(step_weights.values())
        completed_weight = 0
        
        for step in step_sequence:
            if step == current_step:
                # åˆ°è¾¾å½“å‰æ­¥éª¤ï¼Œè¿”å›ä¹‹å‰çš„ç´¯è®¡è¿›åº¦
                break
            else:
                completed_weight += step_weights[step]
        
        # è¿”å›å½“å‰æ­¥éª¤ä¹‹å‰çš„ç´¯è®¡è¿›åº¦
        return (completed_weight / total_weight) * 100

# åˆå§‹åŒ–æœåŠ¡
training_service = TrainingService()

# APIè·¯ç”±
@app.post("/api/v1/task/create", response_model=TaskInfo)
async def create_task(request: TaskCreateRequest):
    """åˆ›å»ºæ–°çš„è®­ç»ƒä»»åŠ¡"""
    task_id = str(uuid.uuid4())
    
    # åˆ›å»ºä»»åŠ¡ä¿¡æ¯
    task_info = TaskInfo(
        task_id=task_id,
        task_name=request.task_name,
        status=TaskStatus.CREATED,
        config=request.config,
        created_at=datetime.now(),
        updated_at=datetime.now()
    )
    
    # ä¿å­˜ä»»åŠ¡
    tasks_db[task_id] = task_info
    
    # åˆ›å»ºä»»åŠ¡ç›®å½•å’Œé…ç½®æ–‡ä»¶
    training_service.create_task_config_file(task_id, request.config)
    
    return task_info

@app.get("/api/v1/task/{task_id}", response_model=TaskInfo)
async def get_task(task_id: str):
    """è·å–ä»»åŠ¡ä¿¡æ¯"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return tasks_db[task_id]

@app.get("/api/v1/tasks", response_model=List[TaskInfo])
async def list_tasks():
    """åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡"""
    return list(tasks_db.values())

@app.post("/api/v1/task/{task_id}/step/{step}")
async def execute_step(task_id: str, step: TrainingStep, request: StepExecuteRequest, background_tasks: BackgroundTasks):
    """æ‰§è¡Œè®­ç»ƒæ­¥éª¤"""
    background_tasks.add_task(training_service.execute_step, task_id, step, request.params)
    return {"message": f"æ­¥éª¤ {step} å¼€å§‹æ‰§è¡Œ", "task_id": task_id}

@app.post("/api/v1/task/{task_id}/cancel")
async def cancel_task(task_id: str):
    """å–æ¶ˆä»»åŠ¡"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # ç»ˆæ­¢æ­£åœ¨è¿è¡Œçš„è¿›ç¨‹
    if task_id in step_processes:
        process = step_processes[task_id]
        process.terminate()
        del step_processes[task_id]
    
    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
    tasks_db[task_id].status = TaskStatus.CANCELLED
    tasks_db[task_id].updated_at = datetime.now()
    
    return {"message": "ä»»åŠ¡å·²å–æ¶ˆ"}

@app.post("/api/v1/task/{task_id}/files/upload")
async def upload_file(task_id: str, file: UploadFile = File(...)):
    """ä¸Šä¼ è®­ç»ƒéŸ³é¢‘æ–‡ä»¶"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # è·å–ä»»åŠ¡è¾“å…¥ç›®å½•
    input_dir = training_service.get_task_input_dir(task_id)
    file_path = input_dir / file.filename
    
    # ä¿å­˜æ–‡ä»¶
    with open(file_path, "wb") as f:
        content = await file.read()
        f.write(content)
    
    return {"message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ", "filename": file.filename, "path": str(file_path)}

@app.get("/api/v1/task/{task_id}/files/download/{filename}")
async def download_file(task_id: str, filename: str):
    """ä¸‹è½½è®­ç»ƒç»“æœæ–‡ä»¶"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # æŸ¥æ‰¾æ–‡ä»¶
    task_dir = training_service.get_task_dir(task_id)
    file_path = None
    
    # åœ¨å„ä¸ªå¯èƒ½çš„ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
    search_dirs = [
        task_dir / "output",
        task_dir / "experiments" / tasks_db[task_id].config.exp_name,
        task_dir
    ]
    
    for search_dir in search_dirs:
        candidate_path = search_dir / filename
        if candidate_path.exists():
            file_path = candidate_path
            break
    
    if not file_path:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    return FileResponse(file_path, filename=filename)

@app.get("/api/v1/task/{task_id}/logs")
async def get_task_logs(task_id: str):
    """è·å–ä»»åŠ¡æ—¥å¿—"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # è¯»å–æ—¥å¿—æ–‡ä»¶
    log_file = training_service.get_task_dir(task_id) / "training.log"
    if log_file.exists():
        with open(log_file, 'r', encoding='utf-8') as f:
            logs = f.read()
        return {"logs": logs}
    else:
        return {"logs": "æš‚æ— æ—¥å¿—"}

@app.delete("/api/v1/task/{task_id}")
async def delete_task(task_id: str):
    """åˆ é™¤ä»»åŠ¡"""
    if task_id not in tasks_db:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # å–æ¶ˆæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
    if tasks_db[task_id].status == TaskStatus.RUNNING:
        await cancel_task(task_id)
    
    # åˆ é™¤ä»»åŠ¡ç›®å½•
    import shutil
    task_dir = training_service.get_task_dir(task_id)
    if task_dir.exists():
        shutil.rmtree(task_dir)
    
    # ä»æ•°æ®åº“ä¸­åˆ é™¤
    del tasks_db[task_id]
    
    return {"message": "ä»»åŠ¡å·²åˆ é™¤"}

@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "GPT-SoVITSè®­ç»ƒæœåŠ¡API",
        "version": "1.0.0",
        "docs_url": "/docs"
    }

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="GPT-SoVITSè®­ç»ƒæœåŠ¡API",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python training_service.py                    # ä½¿ç”¨é»˜è®¤ç«¯å£8000
  python training_service.py --port 8216       # æŒ‡å®šç«¯å£8216
  python training_service.py -p 9000           # ä½¿ç”¨çŸ­å‚æ•°æŒ‡å®šç«¯å£
  python training_service.py --host 127.0.0.1  # æŒ‡å®šä¸»æœºåœ°å€
  python training_service.py --config          # æ˜¾ç¤ºå½“å‰é…ç½®
  python training_service.py --help            # æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        """
    )
    
    parser.add_argument(
        "-p", "--port",
        type=int,
        default=None,
        help="æœåŠ¡ç«¯å£å· (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)"
    )
    
    parser.add_argument(
        "-H", "--host",
        type=str,
        default=None,
        help="ç»‘å®šä¸»æœºåœ°å€ (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)"
    )
    
    parser.add_argument(
        "--workers",
        type=int,
        default=None,
        help="å·¥ä½œè¿›ç¨‹æ•° (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)"
    )
    
    parser.add_argument(
        "--log-level",
        type=str,
        default=None,
        choices=["debug", "info", "warning", "error"],
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–)"
    )
    
    parser.add_argument(
        "--reload",
        action="store_true",
        help="å¼€å‘æ¨¡å¼ï¼šä»£ç å˜æ›´æ—¶è‡ªåŠ¨é‡è½½"
    )
    
    parser.add_argument(
        "--config",
        action="store_true",
        help="æ˜¾ç¤ºå½“å‰é…ç½®ä¿¡æ¯"
    )
    
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_arguments()
    
    # å¦‚æœåªæ˜¯æ˜¾ç¤ºé…ç½®ï¼Œåˆ™æ˜¾ç¤ºåé€€å‡º
    if args.config:
        if os.getenv('GPT_SOVITS_SERVER_MODE') == 'standalone':
            from service_config import print_config
        else:
            from .service_config import print_config
        print_config()
        exit(0)
    
    # å¯¼å…¥é…ç½®
    if os.getenv('GPT_SOVITS_SERVER_MODE') == 'standalone':
        from service_config import SERVICE_CONFIG
    else:
        from .service_config import SERVICE_CONFIG
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶çš„å€¼
    host = args.host or SERVICE_CONFIG["host"]
    port = args.port or SERVICE_CONFIG["port"]
    workers = args.workers or SERVICE_CONFIG["workers"]
    log_level = args.log_level or SERVICE_CONFIG["log_level"]
    
    logger.info(f"ğŸš€ å¯åŠ¨ GPT-SoVITS è®­ç»ƒæœåŠ¡API")
    logger.info(f"ğŸ“ æœåŠ¡åœ°å€: http://{host}:{port}")
    logger.info(f"ğŸ“š APIæ–‡æ¡£: http://{host}:{port}/docs")
    logger.info(f"ğŸ”§ å·¥ä½œè¿›ç¨‹: {workers}")
    logger.info(f"ğŸ“ æ—¥å¿—çº§åˆ«: {log_level}")
    logger.info(f"ğŸ”„ è‡ªåŠ¨é‡è½½: {'å¼€å¯' if args.reload else 'å…³é—­'}")
    logger.info("=" * 50)
    
    if args.reload:
        # ä½¿ç”¨ reload æ¨¡å¼æ—¶ï¼Œå¿…é¡»ä½¿ç”¨æ¨¡å—å¯¼å…¥å­—ç¬¦ä¸²
        uvicorn.run(
            "server.training_service:app",
            host=host, 
            port=port,
            workers=1,  # reload æ¨¡å¼ä¸‹ workers å¿…é¡»ä¸º 1
            log_level=log_level,
            reload=True
        )
    else:
        # é reload æ¨¡å¼æ—¶ï¼Œå¯ä»¥ç›´æ¥ä¼ é€’åº”ç”¨å¯¹è±¡
        uvicorn.run(
            app, 
            host=host, 
            port=port,
            workers=workers,
            log_level=log_level,
            reload=False
        )
